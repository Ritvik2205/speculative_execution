#!/usr/bin/env python3
"""
Robust Vulnerability Detection System
Uses known vulnerable assembly code as ground truth to build comprehensive detection capabilities
"""

import os
import re
import json
import pickle
import numpy as np
from collections import defaultdict, Counter
from dataclasses import dataclass, field
from typing import List, Dict, Set, Tuple, Optional, Any
from pathlib import Path
import networkx as nx
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier, IsolationForest
from sklearn.cluster import DBSCAN
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler
# import capstone  # Optional - will work without it

@dataclass
class VulnerabilitySignature:
    """Comprehensive signature of a vulnerability pattern"""
    vuln_type: str
    architecture: str
    
    # Instruction-level patterns
    opcode_sequence: List[str]
    operand_patterns: List[str]
    instruction_semantics: List[Dict[str, bool]]
    
    # Control flow patterns
    cfg_features: Dict[str, float]
    branch_patterns: List[str]
    call_return_patterns: List[str]
    
    # Data flow patterns
    register_usage: Dict[str, int]
    memory_access_patterns: List[str]
    data_dependencies: List[Tuple[int, int]]
    
    # Microarchitectural patterns
    speculation_indicators: List[str]
    timing_patterns: List[str]
    cache_patterns: List[str]
    
    # Context patterns
    function_context: Dict[str, Any]
    surrounding_code: List[str]
    
    # Statistical features
    statistical_features: Dict[str, float]
    
    # Confidence metrics
    confidence_score: float = 0.0
    source_files: List[str] = field(default_factory=list)

class RobustVulnerabilityDetector:
    """Advanced vulnerability detector using multiple analysis techniques"""
    
    def __init__(self):
        self.vulnerability_signatures = []
        self.ml_classifier = None
        self.anomaly_detector = None
        self.tfidf_vectorizer = None
        self.scaler = None
        
        # Architecture-specific disassemblers (optional)
        self.disassemblers = {}
        try:
            import capstone
            self.disassemblers = {
                'x86': capstone.Cs(capstone.CS_ARCH_X86, capstone.CS_MODE_64),
                'x86_64': capstone.Cs(capstone.CS_ARCH_X86, capstone.CS_MODE_64),
                'arm64': capstone.Cs(capstone.CS_ARCH_ARM64, capstone.CS_MODE_ARM),
                'aarch64': capstone.Cs(capstone.CS_ARCH_ARM64, capstone.CS_MODE_ARM)
            }
            # Enable detailed instruction info
            for cs in self.disassemblers.values():
                cs.detail = True
        except ImportError:
            print("⚠️  Capstone not available - using simplified parsing")
    
    def analyze_vulnerable_code(self, vuln_asm_dir: str) -> List[VulnerabilitySignature]:
        """Extract comprehensive signatures from known vulnerable assembly code"""
        print("🔍 Analyzing known vulnerable assembly code...")
        
        signatures = []
        vuln_files = list(Path(vuln_asm_dir).glob("*.s"))
        
        for asm_file in vuln_files:
            print(f"  📄 Processing {asm_file.name}")
            
            # Extract vulnerability type and architecture from filename
            vuln_type, arch = self._parse_filename(asm_file.name)
            
            # Read and parse assembly
            with open(asm_file, 'r') as f:
                asm_content = f.read()
            
            # Extract multiple signatures per file (different functions/gadgets)
            file_signatures = self._extract_signatures_from_file(
                asm_content, vuln_type, arch, str(asm_file)
            )
            signatures.extend(file_signatures)
        
        print(f"✅ Extracted {len(signatures)} vulnerability signatures")
        return signatures
    
    def _parse_filename(self, filename: str) -> Tuple[str, str]:
        """Parse vulnerability type and architecture from filename"""
        filename_lower = filename.lower()
        
        # Extract vulnerability type
        vuln_type = "UNKNOWN"
        if "spectre_1" in filename_lower or "spectre_v1" in filename_lower:
            vuln_type = "SPECTRE_V1"
        elif "spectre_2" in filename_lower:
            vuln_type = "SPECTRE_V2"
        elif "meltdown" in filename_lower:
            vuln_type = "MELTDOWN"
        elif "retbleed" in filename_lower:
            vuln_type = "RETBLEED"
        elif "bhi" in filename_lower:
            vuln_type = "BHI"
        elif "inception" in filename_lower:
            vuln_type = "INCEPTION"
        elif "l1tf" in filename_lower:
            vuln_type = "L1TF"
        elif "mds" in filename_lower:
            vuln_type = "MDS"
        
        # Extract architecture
        arch = "x86_64"  # default
        if "arm" in filename_lower or "aarch64" in filename_lower:
            arch = "arm64"
        elif "x86" in filename_lower:
            arch = "x86_64"
        
        return vuln_type, arch
    
    def _extract_signatures_from_file(self, asm_content: str, vuln_type: str, 
                                    arch: str, filepath: str) -> List[VulnerabilitySignature]:
        """Extract multiple vulnerability signatures from a single assembly file"""
        signatures = []
        
        # Parse assembly into instructions
        instructions = self._parse_assembly_content(asm_content, arch)
        if not instructions:
            return signatures
        
        # Extract function-level signatures
        functions = self._identify_functions(instructions)
        for func_name, func_instructions in functions.items():
            if len(func_instructions) < 5:  # Skip trivial functions
                continue
                
            signature = self._create_signature_from_instructions(
                func_instructions, vuln_type, arch, filepath, func_name
            )
            if signature:
                signatures.append(signature)
        
        # Extract sliding window signatures for critical patterns
        window_signatures = self._extract_sliding_window_signatures(
            instructions, vuln_type, arch, filepath
        )
        signatures.extend(window_signatures)
        
        return signatures
    
    def _parse_assembly_content(self, asm_content: str, arch: str) -> List[Dict]:
        """Parse assembly content into structured instructions"""
        instructions = []
        lines = asm_content.split('\n')
        
        for i, line in enumerate(lines):
            line = line.strip()
            if not line or line.startswith('.') or line.startswith('#') or ':' in line:
                continue
            
            # Basic instruction parsing
            parts = line.split()
            if not parts:
                continue
                
            opcode = parts[0].lower()
            operands = parts[1:] if len(parts) > 1 else []
            
            instruction = {
                'line_num': i + 1,
                'raw_line': line,
                'opcode': opcode,
                'operands': operands,
                'semantics': self._analyze_instruction_semantics(opcode, operands, arch)
            }
            
            instructions.append(instruction)
        
        return instructions
    
    def _analyze_instruction_semantics(self, opcode: str, operands: List[str], arch: str) -> Dict[str, bool]:
        """Analyze semantic properties of an instruction"""
        semantics = {
            'is_branch': False,
            'is_conditional': False,
            'is_indirect': False,
            'is_call': False,
            'is_return': False,
            'is_load': False,
            'is_store': False,
            'accesses_memory': False,
            'is_arithmetic': False,
            'is_comparison': False,
            'is_speculation_barrier': False,
            'is_cache_operation': False,
            'is_timing_sensitive': False,
            'is_privileged': False
        }
        
        if arch == 'x86_64':
            # x86-64 instruction semantics
            if opcode.startswith('j'):
                semantics['is_branch'] = True
                if opcode != 'jmp':
                    semantics['is_conditional'] = True
            elif opcode in ['call', 'ret']:
                semantics['is_call'] = opcode == 'call'
                semantics['is_return'] = opcode == 'ret'
            elif opcode in ['mov', 'movzx', 'movsx', 'lea']:
                if any('[' in op for op in operands):
                    semantics['accesses_memory'] = True
                    semantics['is_load'] = True
            elif opcode in ['add', 'sub', 'mul', 'div', 'xor', 'and', 'or']:
                semantics['is_arithmetic'] = True
            elif opcode in ['cmp', 'test']:
                semantics['is_comparison'] = True
            elif opcode in ['lfence', 'mfence', 'sfence']:
                semantics['is_speculation_barrier'] = True
            elif opcode in ['clflush', 'clwb']:
                semantics['is_cache_operation'] = True
            elif opcode in ['rdtsc', 'rdtscp']:
                semantics['is_timing_sensitive'] = True
                
        elif arch == 'arm64':
            # ARM64 instruction semantics
            if opcode.startswith('b'):
                semantics['is_branch'] = True
                if '.' in opcode:  # conditional branches like b.eq
                    semantics['is_conditional'] = True
            elif opcode in ['bl', 'blr', 'ret']:
                semantics['is_call'] = opcode in ['bl', 'blr']
                semantics['is_return'] = opcode == 'ret'
            elif opcode in ['ldr', 'ldrb', 'ldrh', 'ldp']:
                semantics['is_load'] = True
                semantics['accesses_memory'] = True
            elif opcode in ['str', 'strb', 'strh', 'stp']:
                semantics['is_store'] = True
                semantics['accesses_memory'] = True
            elif opcode in ['add', 'sub', 'mul', 'div', 'and', 'orr', 'eor']:
                semantics['is_arithmetic'] = True
            elif opcode in ['cmp', 'subs']:
                semantics['is_comparison'] = True
            elif opcode in ['dsb', 'isb', 'dmb']:
                semantics['is_speculation_barrier'] = True
            elif opcode in ['dc', 'ic']:
                semantics['is_cache_operation'] = True
            elif opcode == 'mrs':
                semantics['is_timing_sensitive'] = True
                semantics['is_privileged'] = True
        
        return semantics
    
    def _identify_functions(self, instructions: List[Dict]) -> Dict[str, List[Dict]]:
        """Identify function boundaries in assembly code"""
        functions = {}
        current_function = None
        current_instructions = []
        
        for instr in instructions:
            raw_line = instr['raw_line']
            
            # Look for function labels (simplified heuristic)
            if ':' in raw_line and not raw_line.strip().startswith('.'):
                # Save previous function
                if current_function and current_instructions:
                    functions[current_function] = current_instructions.copy()
                
                # Start new function
                current_function = raw_line.split(':')[0].strip()
                current_instructions = []
            else:
                if current_function:
                    current_instructions.append(instr)
        
        # Save last function
        if current_function and current_instructions:
            functions[current_function] = current_instructions
        
        # If no functions found, treat entire file as one function
        if not functions and instructions:
            functions['main_function'] = instructions
        
        return functions
    
    def _create_signature_from_instructions(self, instructions: List[Dict], vuln_type: str,
                                          arch: str, filepath: str, func_name: str) -> Optional[VulnerabilitySignature]:
        """Create a comprehensive vulnerability signature from instructions"""
        if len(instructions) < 3:
            return None
        
        # Extract instruction-level patterns
        opcode_sequence = [instr['opcode'] for instr in instructions]
        operand_patterns = self._extract_operand_patterns(instructions)
        instruction_semantics = [instr['semantics'] for instr in instructions]
        
        # Build control flow graph
        cfg = self._build_control_flow_graph(instructions)
        cfg_features = self._extract_cfg_features(cfg)
        
        # Extract patterns
        branch_patterns = self._extract_branch_patterns(instructions)
        call_return_patterns = self._extract_call_return_patterns(instructions)
        
        # Analyze data flow
        register_usage = self._analyze_register_usage(instructions)
        memory_access_patterns = self._extract_memory_patterns(instructions)
        data_dependencies = self._extract_data_dependencies(instructions)
        
        # Microarchitectural analysis
        speculation_indicators = self._find_speculation_indicators(instructions)
        timing_patterns = self._find_timing_patterns(instructions)
        cache_patterns = self._find_cache_patterns(instructions)
        
        # Statistical features
        statistical_features = self._compute_statistical_features(instructions)
        
        signature = VulnerabilitySignature(
            vuln_type=vuln_type,
            architecture=arch,
            opcode_sequence=opcode_sequence,
            operand_patterns=operand_patterns,
            instruction_semantics=instruction_semantics,
            cfg_features=cfg_features,
            branch_patterns=branch_patterns,
            call_return_patterns=call_return_patterns,
            register_usage=register_usage,
            memory_access_patterns=memory_access_patterns,
            data_dependencies=data_dependencies,
            speculation_indicators=speculation_indicators,
            timing_patterns=timing_patterns,
            cache_patterns=cache_patterns,
            function_context={'name': func_name, 'size': len(instructions)},
            surrounding_code=[instr['raw_line'] for instr in instructions[:5]],
            statistical_features=statistical_features,
            confidence_score=1.0,  # Known vulnerable code
            source_files=[filepath]
        )
        
        return signature
    
    def _extract_sliding_window_signatures(self, instructions: List[Dict], vuln_type: str,
                                         arch: str, filepath: str) -> List[VulnerabilitySignature]:
        """Extract signatures using sliding window approach for critical patterns"""
        signatures = []
        window_sizes = [5, 10, 15, 20]
        
        for window_size in window_sizes:
            for i in range(len(instructions) - window_size + 1):
                window = instructions[i:i + window_size]
                
                # Check if window contains interesting patterns
                if self._is_interesting_window(window, vuln_type):
                    signature = self._create_signature_from_instructions(
                        window, vuln_type, arch, filepath, f"window_{i}_{window_size}"
                    )
                    if signature:
                        signatures.append(signature)
        
        return signatures
    
    def _is_interesting_window(self, window: List[Dict], vuln_type: str) -> bool:
        """Check if a window contains patterns of interest for the vulnerability type"""
        semantics = [instr['semantics'] for instr in window]
        
        # General interesting patterns
        has_branch = any(s['is_branch'] for s in semantics)
        has_memory = any(s['accesses_memory'] for s in semantics)
        has_comparison = any(s['is_comparison'] for s in semantics)
        
        if vuln_type == "SPECTRE_V1":
            return has_comparison and has_branch and has_memory
        elif vuln_type == "SPECTRE_V2":
            return any(s['is_indirect'] for s in semantics) and has_branch
        elif vuln_type == "MELTDOWN":
            return has_memory and any(s['is_privileged'] for s in semantics)
        elif vuln_type == "BHI":
            return has_branch and len([s for s in semantics if s['is_branch']]) >= 2
        elif vuln_type == "INCEPTION":
            return any(s['is_return'] for s in semantics) and any(s['is_call'] for s in semantics)
        
        return has_branch or has_memory  # Default heuristic
    
    def _extract_operand_patterns(self, instructions: List[Dict]) -> List[str]:
        """Extract operand usage patterns"""
        patterns = []
        for instr in instructions:
            for operand in instr['operands']:
                if '[' in operand:  # Memory access
                    patterns.append('MEM_ACCESS')
                elif operand.startswith('%') or operand.startswith('r') or operand.startswith('x'):
                    patterns.append('REGISTER')
                elif operand.isdigit() or operand.startswith('0x'):
                    patterns.append('IMMEDIATE')
        return patterns
    
    def _build_control_flow_graph(self, instructions: List[Dict]) -> nx.DiGraph:
        """Build control flow graph from instructions"""
        cfg = nx.DiGraph()
        
        # Add nodes for each instruction
        for i, instr in enumerate(instructions):
            cfg.add_node(i, **instr)
        
        # Add edges for control flow
        for i in range(len(instructions) - 1):
            instr = instructions[i]
            if not instr['semantics']['is_branch']:
                cfg.add_edge(i, i + 1)  # Sequential flow
            else:
                # For branches, add edge to next instruction (fall-through)
                if instr['semantics']['is_conditional']:
                    cfg.add_edge(i, i + 1)
                # TODO: Add edges to branch targets (requires more sophisticated parsing)
        
        return cfg
    
    def _extract_cfg_features(self, cfg: nx.DiGraph) -> Dict[str, float]:
        """Extract features from control flow graph"""
        features = {}
        
        if len(cfg.nodes()) == 0:
            return features
        
        features['num_nodes'] = len(cfg.nodes())
        features['num_edges'] = len(cfg.edges())
        features['density'] = nx.density(cfg)
        
        try:
            features['avg_clustering'] = nx.average_clustering(cfg.to_undirected())
        except:
            features['avg_clustering'] = 0.0
        
        # Branch statistics
        branch_nodes = [n for n, data in cfg.nodes(data=True) 
                       if data.get('semantics', {}).get('is_branch', False)]
        features['branch_density'] = len(branch_nodes) / len(cfg.nodes())
        
        return features
    
    def _extract_branch_patterns(self, instructions: List[Dict]) -> List[str]:
        """Extract branch instruction patterns"""
        patterns = []
        for instr in instructions:
            if instr['semantics']['is_branch']:
                pattern = f"{instr['opcode']}"
                if instr['semantics']['is_conditional']:
                    pattern += "_COND"
                if instr['semantics']['is_indirect']:
                    pattern += "_INDIRECT"
                patterns.append(pattern)
        return patterns
    
    def _extract_call_return_patterns(self, instructions: List[Dict]) -> List[str]:
        """Extract call/return patterns"""
        patterns = []
        for instr in instructions:
            if instr['semantics']['is_call']:
                patterns.append(f"CALL_{instr['opcode']}")
            elif instr['semantics']['is_return']:
                patterns.append(f"RET_{instr['opcode']}")
        return patterns
    
    def _analyze_register_usage(self, instructions: List[Dict]) -> Dict[str, int]:
        """Analyze register usage patterns"""
        register_counts = Counter()
        
        for instr in instructions:
            for operand in instr['operands']:
                # Simplified register detection
                if any(operand.startswith(prefix) for prefix in ['%r', '%e', 'x', 'w']):
                    register_counts[operand] += 1
        
        return dict(register_counts)
    
    def _extract_memory_patterns(self, instructions: List[Dict]) -> List[str]:
        """Extract memory access patterns"""
        patterns = []
        for instr in instructions:
            if instr['semantics']['accesses_memory']:
                if instr['semantics']['is_load']:
                    patterns.append('LOAD')
                elif instr['semantics']['is_store']:
                    patterns.append('STORE')
                else:
                    patterns.append('MEMORY_ACCESS')
        return patterns
    
    def _extract_data_dependencies(self, instructions: List[Dict]) -> List[Tuple[int, int]]:
        """Extract data dependencies between instructions"""
        dependencies = []
        # Simplified dependency analysis
        for i in range(len(instructions) - 1):
            for j in range(i + 1, min(i + 5, len(instructions))):  # Look ahead 5 instructions
                if self._has_data_dependency(instructions[i], instructions[j]):
                    dependencies.append((i, j))
        return dependencies
    
    def _has_data_dependency(self, instr1: Dict, instr2: Dict) -> bool:
        """Check if two instructions have data dependency"""
        # Simplified check - if operands overlap
        operands1 = set(instr1['operands'])
        operands2 = set(instr2['operands'])
        return bool(operands1.intersection(operands2))
    
    def _find_speculation_indicators(self, instructions: List[Dict]) -> List[str]:
        """Find indicators of speculative execution exploitation"""
        indicators = []
        for instr in instructions:
            if instr['semantics']['is_speculation_barrier']:
                indicators.append(f"BARRIER_{instr['opcode']}")
            elif instr['semantics']['is_branch'] and instr['semantics']['is_conditional']:
                indicators.append("SPECULATIVE_BRANCH")
        return indicators
    
    def _find_timing_patterns(self, instructions: List[Dict]) -> List[str]:
        """Find timing-related instruction patterns"""
        patterns = []
        for instr in instructions:
            if instr['semantics']['is_timing_sensitive']:
                patterns.append(f"TIMING_{instr['opcode']}")
        return patterns
    
    def _find_cache_patterns(self, instructions: List[Dict]) -> List[str]:
        """Find cache-related instruction patterns"""
        patterns = []
        for instr in instructions:
            if instr['semantics']['is_cache_operation']:
                patterns.append(f"CACHE_{instr['opcode']}")
        return patterns
    
    def _compute_statistical_features(self, instructions: List[Dict]) -> Dict[str, float]:
        """Compute statistical features from instructions"""
        features = {}
        
        features['instruction_count'] = len(instructions)
        
        # Opcode distribution
        opcodes = [instr['opcode'] for instr in instructions]
        opcode_counts = Counter(opcodes)
        features['unique_opcodes'] = len(opcode_counts)
        features['most_common_opcode_freq'] = opcode_counts.most_common(1)[0][1] / len(opcodes) if opcodes else 0
        
        # Semantic features
        semantics = [instr['semantics'] for instr in instructions]
        for key in ['is_branch', 'is_load', 'is_store', 'accesses_memory']:
            features[f'{key}_ratio'] = sum(1 for s in semantics if s.get(key, False)) / len(semantics)
        
        return features
    
    def build_ml_classifier(self, signatures: List[VulnerabilitySignature]):
        """Build machine learning classifier from vulnerability signatures"""
        print("🤖 Building ML classifier from vulnerability signatures...")
        
        # Prepare training data
        X, y = self._prepare_training_data(signatures)
        
        if len(X) == 0:
            print("❌ No training data available")
            return
        
        # Scale features
        self.scaler = StandardScaler()
        X_scaled = self.scaler.fit_transform(X)
        
        # Train classifier
        self.ml_classifier = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )
        self.ml_classifier.fit(X_scaled, y)
        
        # Train anomaly detector
        self.anomaly_detector = IsolationForest(
            contamination=0.1,
            random_state=42
        )
        self.anomaly_detector.fit(X_scaled)
        
        print(f"✅ Trained classifier on {len(X)} samples")
        print(f"   Feature importance: {dict(zip(range(len(X[0])), self.ml_classifier.feature_importances_[:5]))}")
    
    def _prepare_training_data(self, signatures: List[VulnerabilitySignature]) -> Tuple[List, List]:
        """Prepare training data from signatures"""
        X = []
        y = []
        
        for sig in signatures:
            features = self._signature_to_feature_vector(sig)
            if features:
                X.append(features)
                y.append(sig.vuln_type)
        
        return X, y
    
    def _signature_to_feature_vector(self, sig: VulnerabilitySignature) -> Optional[List[float]]:
        """Convert signature to numerical feature vector"""
        features = []
        
        # Statistical features
        features.extend(sig.statistical_features.values())
        
        # CFG features
        features.extend(sig.cfg_features.values())
        
        # Pattern counts
        features.append(len(sig.branch_patterns))
        features.append(len(sig.call_return_patterns))
        features.append(len(sig.memory_access_patterns))
        features.append(len(sig.speculation_indicators))
        features.append(len(sig.timing_patterns))
        features.append(len(sig.cache_patterns))
        
        # Ensure consistent feature vector size
        target_size = 50
        if len(features) < target_size:
            features.extend([0.0] * (target_size - len(features)))
        elif len(features) > target_size:
            features = features[:target_size]
        
        return features
    
    def detect_vulnerabilities(self, target_instructions: List[Dict], 
                             architecture: str) -> List[Dict[str, Any]]:
        """Detect vulnerabilities in target assembly code"""
        print("🎯 Detecting vulnerabilities in target code...")
        
        detections = []
        
        # Sliding window analysis
        window_sizes = [10, 15, 20]
        for window_size in window_sizes:
            for i in range(len(target_instructions) - window_size + 1):
                window = target_instructions[i:i + window_size]
                
                detection = self._analyze_window_for_vulnerabilities(
                    window, architecture, i, window_size
                )
                if detection:
                    detections.append(detection)
        
        # Rank and filter detections
        detections = self._rank_and_filter_detections(detections)
        
        print(f"🔍 Found {len(detections)} potential vulnerabilities")
        return detections
    
    def _analyze_window_for_vulnerabilities(self, window: List[Dict], architecture: str,
                                          start_idx: int, window_size: int) -> Optional[Dict[str, Any]]:
        """Analyze a window of instructions for vulnerabilities"""
        # Create temporary signature for the window
        temp_sig = self._create_signature_from_instructions(
            window, "UNKNOWN", architecture, "target", f"window_{start_idx}"
        )
        
        if not temp_sig:
            return None
        
        detection = {
            'start_idx': start_idx,
            'end_idx': start_idx + window_size,
            'window_size': window_size,
            'instructions': [instr['raw_line'] for instr in window],
            'confidence_scores': {},
            'vulnerability_types': [],
            'evidence': {}
        }
        
        # Pattern matching against known signatures
        pattern_scores = self._match_against_signatures(temp_sig)
        detection['confidence_scores'].update(pattern_scores)
        
        # ML classification
        if self.ml_classifier and self.scaler:
            ml_scores = self._ml_classify_window(temp_sig)
            detection['confidence_scores'].update(ml_scores)
        
        # Anomaly detection
        if self.anomaly_detector and self.scaler:
            anomaly_score = self._detect_anomaly(temp_sig)
            detection['confidence_scores']['anomaly'] = anomaly_score
        
        # Determine best vulnerability type
        if detection['confidence_scores']:
            best_type = max(detection['confidence_scores'].items(), key=lambda x: x[1])
            if best_type[1] > 0.3:  # Threshold
                detection['vulnerability_types'] = [best_type[0]]
                detection['primary_confidence'] = best_type[1]
                return detection
        
        return None
    
    def _match_against_signatures(self, target_sig: VulnerabilitySignature) -> Dict[str, float]:
        """Match target signature against known vulnerability signatures"""
        scores = defaultdict(float)
        
        for known_sig in self.vulnerability_signatures:
            similarity = self._compute_signature_similarity(target_sig, known_sig)
            scores[known_sig.vuln_type] = max(scores[known_sig.vuln_type], similarity)
        
        return dict(scores)
    
    def _compute_signature_similarity(self, sig1: VulnerabilitySignature, 
                                    sig2: VulnerabilitySignature) -> float:
        """Compute similarity between two signatures"""
        if sig1.architecture != sig2.architecture:
            return 0.0
        
        similarities = []
        
        # Opcode sequence similarity
        opcode_sim = self._sequence_similarity(sig1.opcode_sequence, sig2.opcode_sequence)
        similarities.append(opcode_sim * 0.3)
        
        # Pattern similarities
        branch_sim = self._set_similarity(sig1.branch_patterns, sig2.branch_patterns)
        similarities.append(branch_sim * 0.2)
        
        memory_sim = self._set_similarity(sig1.memory_access_patterns, sig2.memory_access_patterns)
        similarities.append(memory_sim * 0.2)
        
        # Statistical feature similarity
        stat_sim = self._statistical_similarity(sig1.statistical_features, sig2.statistical_features)
        similarities.append(stat_sim * 0.3)
        
        return sum(similarities)
    
    def _sequence_similarity(self, seq1: List[str], seq2: List[str]) -> float:
        """Compute similarity between two sequences"""
        if not seq1 or not seq2:
            return 0.0
        
        # Use longest common subsequence
        from difflib import SequenceMatcher
        matcher = SequenceMatcher(None, seq1, seq2)
        return matcher.ratio()
    
    def _set_similarity(self, set1: List[str], set2: List[str]) -> float:
        """Compute Jaccard similarity between two sets"""
        s1, s2 = set(set1), set(set2)
        if not s1 and not s2:
            return 1.0
        if not s1 or not s2:
            return 0.0
        return len(s1.intersection(s2)) / len(s1.union(s2))
    
    def _statistical_similarity(self, stats1: Dict[str, float], stats2: Dict[str, float]) -> float:
        """Compute similarity between statistical features"""
        common_keys = set(stats1.keys()).intersection(set(stats2.keys()))
        if not common_keys:
            return 0.0
        
        similarities = []
        for key in common_keys:
            v1, v2 = stats1[key], stats2[key]
            if v1 == 0 and v2 == 0:
                similarities.append(1.0)
            elif v1 == 0 or v2 == 0:
                similarities.append(0.0)
            else:
                similarities.append(1.0 - abs(v1 - v2) / max(v1, v2))
        
        return sum(similarities) / len(similarities)
    
    def _ml_classify_window(self, temp_sig: VulnerabilitySignature) -> Dict[str, float]:
        """Use ML classifier to score window"""
        features = self._signature_to_feature_vector(temp_sig)
        if not features:
            return {}
        
        features_scaled = self.scaler.transform([features])
        probabilities = self.ml_classifier.predict_proba(features_scaled)[0]
        
        scores = {}
        for i, vuln_type in enumerate(self.ml_classifier.classes_):
            scores[f"ml_{vuln_type}"] = probabilities[i]
        
        return scores
    
    def _detect_anomaly(self, temp_sig: VulnerabilitySignature) -> float:
        """Detect if signature is anomalous (potentially vulnerable)"""
        features = self._signature_to_feature_vector(temp_sig)
        if not features:
            return 0.0
        
        features_scaled = self.scaler.transform([features])
        anomaly_score = self.anomaly_detector.decision_function(features_scaled)[0]
        
        # Convert to 0-1 range (lower scores = more anomalous)
        return max(0.0, min(1.0, (anomaly_score + 0.5) / 1.0))
    
    def _rank_and_filter_detections(self, detections: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Rank and filter detections by confidence"""
        # Sort by primary confidence
        detections = [d for d in detections if d.get('primary_confidence', 0) > 0.3]
        detections.sort(key=lambda x: x.get('primary_confidence', 0), reverse=True)
        
        # Remove overlapping detections (keep highest confidence)
        filtered = []
        for detection in detections:
            overlaps = False
            for existing in filtered:
                if self._detections_overlap(detection, existing):
                    overlaps = True
                    break
            if not overlaps:
                filtered.append(detection)
        
        return filtered[:20]  # Top 20 detections
    
    def _detections_overlap(self, det1: Dict, det2: Dict) -> bool:
        """Check if two detections overlap significantly"""
        start1, end1 = det1['start_idx'], det1['end_idx']
        start2, end2 = det2['start_idx'], det2['end_idx']
        
        overlap = max(0, min(end1, end2) - max(start1, start2))
        min_length = min(end1 - start1, end2 - start2)
        
        return overlap / min_length > 0.5  # 50% overlap threshold
    
    def save_model(self, filepath: str):
        """Save the trained model and signatures"""
        model_data = {
            'vulnerability_signatures': self.vulnerability_signatures,
            'ml_classifier': self.ml_classifier,
            'anomaly_detector': self.anomaly_detector,
            'scaler': self.scaler
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"💾 Saved model to {filepath}")
    
    def load_model(self, filepath: str):
        """Load a trained model and signatures"""
        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)
        
        self.vulnerability_signatures = model_data['vulnerability_signatures']
        self.ml_classifier = model_data['ml_classifier']
        self.anomaly_detector = model_data['anomaly_detector']
        self.scaler = model_data['scaler']
        
        print(f"📂 Loaded model from {filepath}")

def main():
    """Main execution function"""
    print("🚀 Starting Robust Vulnerability Detection System")
    
    # Initialize detector
    detector = RobustVulnerabilityDetector()
    
    # Analyze known vulnerable code
    vuln_asm_dir = "../c_vulns/asm_code"
    if os.path.exists(vuln_asm_dir):
        signatures = detector.analyze_vulnerable_code(vuln_asm_dir)
        detector.vulnerability_signatures = signatures
        
        # Build ML classifier
        detector.build_ml_classifier(signatures)
        
        # Save model
        detector.save_model("robust_vulnerability_model.pkl")
        
        # Save signatures for analysis
        with open("vulnerability_signatures.json", 'w') as f:
            # Convert signatures to serializable format
            serializable_sigs = []
            for sig in signatures:
                sig_dict = {
                    'vuln_type': sig.vuln_type,
                    'architecture': sig.architecture,
                    'opcode_sequence': sig.opcode_sequence[:10],  # First 10 opcodes
                    'statistical_features': sig.statistical_features,
                    'confidence_score': sig.confidence_score,
                    'source_files': sig.source_files
                }
                serializable_sigs.append(sig_dict)
            
            json.dump(serializable_sigs, f, indent=2)
        
        print(f"📊 Analysis complete:")
        print(f"   Vulnerability signatures: {len(signatures)}")
        print(f"   Vulnerability types: {len(set(sig.vuln_type for sig in signatures))}")
        print(f"   Architectures: {len(set(sig.architecture for sig in signatures))}")
        
    else:
        print(f"❌ Vulnerable assembly directory not found: {vuln_asm_dir}")

if __name__ == "__main__":
    main()