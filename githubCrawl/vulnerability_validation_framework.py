#!/usr/bin/env python3
"""
Vulnerability Validation Framework
Validates that detected vulnerabilities in GitHub assembly code are actually exploitable
"""

import os
import re
import json
import sqlite3
import subprocess
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from collections import defaultdict
import logging

@dataclass
class ValidationResult:
    """Result of vulnerability validation"""
    detection_id: int
    vulnerability_type: str
    validation_methods: List[str]
    is_exploitable: bool
    confidence_level: str  # HIGH, MEDIUM, LOW
    evidence: Dict[str, Any]
    false_positive_likelihood: float
    validation_notes: str
    source_code_context: Optional[str] = None
    exploit_vector: Optional[str] = None

class VulnerabilityValidator:
    """Comprehensive framework for validating detected vulnerabilities"""
    
    def __init__(self, db_path: str = "vulnerability_scan_results.db"):
        self.db_path = db_path
        self.validation_methods = {
            'source_code_analysis': self._validate_via_source_code,
            'microarchitectural_analysis': self._validate_via_microarch,
            'exploit_simulation': self._validate_via_exploit_sim,
            'compiler_analysis': self._validate_via_compiler,
            'static_analysis_tools': self._validate_via_static_tools,
            'expert_pattern_matching': self._validate_via_expert_patterns,
            'context_analysis': self._validate_via_context,
            'comparative_analysis': self._validate_via_comparison
        }
        
        # Setup logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('vulnerability_validation.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def validate_all_detections(self) -> List[ValidationResult]:
        """Validate all vulnerability detections in the database"""
        self.logger.info("Starting comprehensive vulnerability validation...")
        
        # Load all detections
        detections = self._load_detections()
        if not detections:
            self.logger.warning("No vulnerability detections found to validate")
            return []
        
        validation_results = []
        
        for i, detection in enumerate(detections, 1):
            self.logger.info(f"Validating detection {i}/{len(detections)}: {detection['vulnerability_type']}")
            
            try:
                result = self._validate_single_detection(detection)
                validation_results.append(result)
                
                # Save intermediate results
                self._save_validation_result(result)
                
            except Exception as e:
                self.logger.error(f"Failed to validate detection {detection['id']}: {e}")
        
        # Generate validation report
        self._generate_validation_report(validation_results)
        
        return validation_results
    
    def _load_detections(self) -> List[Dict[str, Any]]:
        """Load vulnerability detections from database"""
        if not os.path.exists(self.db_path):
            return []
        
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row  # Enable column access by name
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT id, repository, source_file, assembly_file, vulnerability_type, 
                   confidence, risk_level, location_start, location_end, 
                   evidence, detector_used, timestamp
            FROM vulnerabilities
            ORDER BY confidence DESC
        """)
        
        detections = [dict(row) for row in cursor.fetchall()]
        conn.close()
        
        return detections
    
    def _validate_single_detection(self, detection: Dict[str, Any]) -> ValidationResult:
        """Validate a single vulnerability detection using multiple methods"""
        
        validation_evidence = {}
        validation_methods_used = []
        exploitable_votes = 0
        total_votes = 0
        
        # Method 1: Source Code Analysis
        try:
            is_exploitable, evidence = self._validate_via_source_code(detection)
            validation_evidence['source_code'] = evidence
            validation_methods_used.append('source_code_analysis')
            if is_exploitable is not None:
                if is_exploitable:
                    exploitable_votes += 1
                total_votes += 1
        except Exception as e:
            self.logger.warning(f"Source code validation failed: {e}")
        
        # Method 2: Microarchitectural Analysis  
        try:
            is_exploitable, evidence = self._validate_via_microarch(detection)
            validation_evidence['microarchitectural'] = evidence
            validation_methods_used.append('microarchitectural_analysis')
            if is_exploitable is not None:
                if is_exploitable:
                    exploitable_votes += 1
                total_votes += 1
        except Exception as e:
            self.logger.warning(f"Microarchitectural validation failed: {e}")
        
        # Method 3: Expert Pattern Matching
        try:
            is_exploitable, evidence = self._validate_via_expert_patterns(detection)
            validation_evidence['expert_patterns'] = evidence
            validation_methods_used.append('expert_pattern_matching')
            if is_exploitable is not None:
                if is_exploitable:
                    exploitable_votes += 1
                total_votes += 1
        except Exception as e:
            self.logger.warning(f"Expert pattern validation failed: {e}")
        
        # Method 4: Context Analysis
        try:
            is_exploitable, evidence = self._validate_via_context(detection)
            validation_evidence['context'] = evidence
            validation_methods_used.append('context_analysis')
            if is_exploitable is not None:
                if is_exploitable:
                    exploitable_votes += 1
                total_votes += 1
        except Exception as e:
            self.logger.warning(f"Context validation failed: {e}")
        
        # Method 5: Static Analysis Tools
        try:
            is_exploitable, evidence = self._validate_via_static_tools(detection)
            validation_evidence['static_tools'] = evidence
            validation_methods_used.append('static_analysis_tools')
            if is_exploitable is not None:
                if is_exploitable:
                    exploitable_votes += 1
                total_votes += 1
        except Exception as e:
            self.logger.warning(f"Static analysis validation failed: {e}")
        
        # Calculate consensus
        if total_votes == 0:
            is_exploitable = False
            confidence_level = "LOW"
            false_positive_likelihood = 0.9
        else:
            consensus_score = exploitable_votes / total_votes
            is_exploitable = consensus_score >= 0.5
            
            if consensus_score >= 0.8:
                confidence_level = "HIGH"
                false_positive_likelihood = 1.0 - consensus_score
            elif consensus_score >= 0.6:
                confidence_level = "MEDIUM"
                false_positive_likelihood = 1.0 - consensus_score
            else:
                confidence_level = "LOW"
                false_positive_likelihood = 1.0 - consensus_score
        
        # Generate validation notes
        validation_notes = self._generate_validation_notes(
            detection, validation_evidence, consensus_score if total_votes > 0 else 0.0
        )
        
        return ValidationResult(
            detection_id=detection['id'],
            vulnerability_type=detection['vulnerability_type'],
            validation_methods=validation_methods_used,
            is_exploitable=is_exploitable,
            confidence_level=confidence_level,
            evidence=validation_evidence,
            false_positive_likelihood=false_positive_likelihood,
            validation_notes=validation_notes
        )
    
    def _validate_via_source_code(self, detection: Dict[str, Any]) -> Tuple[Optional[bool], Dict[str, Any]]:
        """Validate by analyzing the original source code"""
        evidence = {'method': 'source_code_analysis'}
        
        # Try to find the original source file
        source_file = detection.get('source_file', 'unknown')
        repository = detection.get('repository', 'unknown')
        
        if source_file == 'unknown' or repository == 'unknown':
            evidence['status'] = 'source_file_not_found'
            return None, evidence
        
        # Construct path to source file
        repo_path = Path("repos") / repository
        source_paths = list(repo_path.rglob(f"*{source_file}*"))
        
        if not source_paths:
            evidence['status'] = 'source_file_not_accessible'
            return None, evidence
        
        # Analyze source code for vulnerability patterns
        source_path = source_paths[0]
        try:
            with open(source_path, 'r', encoding='utf-8', errors='ignore') as f:
                source_content = f.read()
            
            evidence['source_file_found'] = str(source_path)
            evidence['source_lines'] = len(source_content.split('\n'))
            
            # Look for vulnerability indicators in source
            vuln_type = detection['vulnerability_type']
            indicators = self._find_source_vulnerability_indicators(source_content, vuln_type)
            evidence['vulnerability_indicators'] = indicators
            
            # Check for mitigations
            mitigations = self._find_source_mitigations(source_content, vuln_type)
            evidence['mitigations_found'] = mitigations
            
            # Calculate exploitability based on indicators vs mitigations
            indicator_score = len(indicators) * 0.3
            mitigation_penalty = len(mitigations) * 0.5
            exploitability_score = max(0, indicator_score - mitigation_penalty)
            
            evidence['exploitability_score'] = exploitability_score
            evidence['status'] = 'analyzed'
            
            return exploitability_score > 0.4, evidence
            
        except Exception as e:
            evidence['error'] = str(e)
            evidence['status'] = 'analysis_failed'
            return None, evidence
    
    def _find_source_vulnerability_indicators(self, source_content: str, vuln_type: str) -> List[str]:
        """Find vulnerability indicators in source code"""
        indicators = []
        
        if vuln_type == "SPECTRE_V1":
            # Look for bounds check bypass patterns
            if re.search(r'if\s*\([^)]*<[^)]*\)\s*{[^}]*\[[^]]*\]', source_content):
                indicators.append("bounds_check_with_array_access")
            if 'volatile' in source_content and '[' in source_content:
                indicators.append("volatile_array_access")
            if re.search(r'clflush|rdtsc', source_content, re.IGNORECASE):
                indicators.append("cache_timing_operations")
        
        elif vuln_type == "SPECTRE_V2":
            # Look for indirect branch patterns
            if re.search(r'function.*pointer|void\s*\*.*\(', source_content):
                indicators.append("function_pointers")
            if re.search(r'jump.*table|switch.*case', source_content):
                indicators.append("jump_tables")
        
        elif vuln_type == "MELTDOWN":
            # Look for privileged memory access
            if re.search(r'mmap|/proc/|/sys/', source_content):
                indicators.append("privileged_memory_access")
            if re.search(r'signal|SIGSEGV|sigaction', source_content):
                indicators.append("exception_handling")
        
        elif vuln_type == "L1TF":
            # Look for page fault exploitation
            if re.search(r'mmap.*MAP_FAILED|munmap|mprotect', source_content):
                indicators.append("memory_mapping_operations")
            if re.search(r'cache.*flush|clflush', source_content, re.IGNORECASE):
                indicators.append("cache_operations")
        
        elif vuln_type == "BHI":
            # Look for branch history manipulation
            if source_content.count('for') > 3 and 'if' in source_content:
                indicators.append("complex_branching_patterns")
            if re.search(r'indirect.*call|call.*\*', source_content):
                indicators.append("indirect_calls")
        
        return indicators
    
    def _find_source_mitigations(self, source_content: str, vuln_type: str) -> List[str]:
        """Find vulnerability mitigations in source code"""
        mitigations = []
        
        # General mitigations
        if re.search(r'lfence|mfence|sfence', source_content, re.IGNORECASE):
            mitigations.append("speculation_barriers")
        
        if re.search(r'bounds.*check|size.*check|length.*check', source_content, re.IGNORECASE):
            mitigations.append("explicit_bounds_checking")
        
        if re.search(r'retpoline|indirect.*branch.*mitigation', source_content, re.IGNORECASE):
            mitigations.append("retpoline_mitigation")
        
        if re.search(r'KPTI|kaiser|page.*table.*isolation', source_content, re.IGNORECASE):
            mitigations.append("page_table_isolation")
        
        # Compiler mitigations
        if re.search(r'__builtin_speculation_safe|__attribute__.*speculation', source_content):
            mitigations.append("compiler_speculation_barriers")
        
        return mitigations
    
    def _validate_via_microarch(self, detection: Dict[str, Any]) -> Tuple[Optional[bool], Dict[str, Any]]:
        """Validate by analyzing microarchitectural implications"""
        evidence = {'method': 'microarchitectural_analysis'}
        
        assembly_file = detection.get('assembly_file', '')
        vuln_type = detection['vulnerability_type']
        
        if not os.path.exists(assembly_file):
            evidence['status'] = 'assembly_file_not_found'
            return None, evidence
        
        try:
            # Read assembly file
            with open(assembly_file, 'r', encoding='utf-8', errors='ignore') as f:
                asm_content = f.read()
            
            # Extract microarchitectural features
            microarch_features = self._extract_microarch_features(asm_content, vuln_type)
            evidence.update(microarch_features)
            
            # Calculate exploitability based on microarchitectural evidence
            exploitability_score = self._calculate_microarch_exploitability(microarch_features, vuln_type)
            evidence['exploitability_score'] = exploitability_score
            evidence['status'] = 'analyzed'
            
            return exploitability_score > 0.5, evidence
            
        except Exception as e:
            evidence['error'] = str(e)
            evidence['status'] = 'analysis_failed'
            return None, evidence
    
    def _extract_microarch_features(self, asm_content: str, vuln_type: str) -> Dict[str, Any]:
        """Extract microarchitectural features from assembly code"""
        features = {}
        lines = asm_content.split('\n')
        
        # Count different instruction types
        features['total_instructions'] = len([l for l in lines if l.strip() and not l.strip().startswith('.')])
        features['branch_instructions'] = len([l for l in lines if re.search(r'\b(j|b\.)', l)])
        features['memory_instructions'] = len([l for l in lines if re.search(r'\b(ldr|str|mov.*\[)', l)])
        features['indirect_branches'] = len([l for l in lines if re.search(r'\b(br|blr|jmp.*%)', l)])
        
        # Look for speculation-related patterns
        features['speculation_barriers'] = len([l for l in lines if re.search(r'\b(dsb|isb|[sl]fence)', l)])
        features['cache_operations'] = len([l for l in lines if re.search(r'\b(dc|ic|clflush)', l)])
        features['timing_instructions'] = len([l for l in lines if re.search(r'\b(mrs.*cntvct|rdtsc)', l)])
        
        # Calculate ratios
        if features['total_instructions'] > 0:
            features['branch_ratio'] = features['branch_instructions'] / features['total_instructions']
            features['memory_ratio'] = features['memory_instructions'] / features['total_instructions']
            features['indirect_ratio'] = features['indirect_branches'] / features['total_instructions']
        
        # Architecture-specific analysis
        if 'arm64' in asm_content.lower() or any('x' in l and 'w' in l for l in lines[:10]):
            features['architecture'] = 'arm64'
            features['speculation_window'] = self._estimate_arm64_speculation_window(lines)
        else:
            features['architecture'] = 'x86_64'
            features['speculation_window'] = self._estimate_x86_speculation_window(lines)
        
        return features
    
    def _estimate_arm64_speculation_window(self, lines: List[str]) -> Dict[str, Any]:
        """Estimate speculation window characteristics for ARM64"""
        speculation_info = {}
        
        # Look for branch misprediction opportunities
        conditional_branches = [l for l in lines if re.search(r'\bb\.[a-z]+', l)]
        speculation_info['conditional_branches'] = len(conditional_branches)
        
        # Estimate speculation depth
        max_speculation_depth = 0
        current_depth = 0
        
        for line in lines:
            if re.search(r'\bb\.[a-z]+', line):  # Conditional branch
                current_depth += 1
                max_speculation_depth = max(max_speculation_depth, current_depth)
            elif re.search(r'\b(dsb|isb)', line):  # Speculation barrier
                current_depth = 0
        
        speculation_info['max_speculation_depth'] = max_speculation_depth
        speculation_info['speculation_vulnerable'] = max_speculation_depth > 5
        
        return speculation_info
    
    def _estimate_x86_speculation_window(self, lines: List[str]) -> Dict[str, Any]:
        """Estimate speculation window characteristics for x86_64"""
        speculation_info = {}
        
        # Look for branch misprediction opportunities
        conditional_branches = [l for l in lines if re.search(r'\bj[a-z]+\b(?!mp)', l)]
        speculation_info['conditional_branches'] = len(conditional_branches)
        
        # Look for speculation barriers
        barriers = [l for l in lines if re.search(r'\b[lms]fence\b', l)]
        speculation_info['speculation_barriers'] = len(barriers)
        speculation_info['speculation_vulnerable'] = len(conditional_branches) > len(barriers)
        
        return speculation_info
    
    def _calculate_microarch_exploitability(self, features: Dict[str, Any], vuln_type: str) -> float:
        """Calculate exploitability score based on microarchitectural features"""
        score = 0.0
        
        if vuln_type == "SPECTRE_V1":
            # Spectre V1 needs bounds check bypass + speculation
            if features.get('branch_ratio', 0) > 0.1:  # Has branches
                score += 0.3
            if features.get('memory_ratio', 0) > 0.2:  # Has memory accesses
                score += 0.3
            if features.get('speculation_window', {}).get('speculation_vulnerable', False):
                score += 0.4
        
        elif vuln_type == "SPECTRE_V2":
            # Spectre V2 needs indirect branches
            if features.get('indirect_ratio', 0) > 0.05:  # Has indirect branches
                score += 0.5
            if features.get('speculation_barriers', 0) == 0:  # No mitigations
                score += 0.3
        
        elif vuln_type == "BHI":
            # BHI needs complex branching patterns
            if features.get('branch_ratio', 0) > 0.2:  # High branch density
                score += 0.4
            if features.get('speculation_window', {}).get('conditional_branches', 0) > 10:
                score += 0.3
        
        elif vuln_type == "L1TF":
            # L1TF needs memory access patterns
            if features.get('memory_ratio', 0) > 0.3:  # High memory density
                score += 0.4
            if features.get('cache_operations', 0) > 0:  # Cache operations present
                score += 0.3
        
        return min(score, 1.0)
    
    def _validate_via_expert_patterns(self, detection: Dict[str, Any]) -> Tuple[Optional[bool], Dict[str, Any]]:
        """Validate using expert-defined vulnerability patterns"""
        evidence = {'method': 'expert_pattern_matching'}
        
        vuln_type = detection['vulnerability_type']
        assembly_file = detection.get('assembly_file', '')
        
        if not os.path.exists(assembly_file):
            evidence['status'] = 'assembly_file_not_found'
            return None, evidence
        
        try:
            with open(assembly_file, 'r', encoding='utf-8', errors='ignore') as f:
                asm_content = f.read()
            
            # Expert patterns for each vulnerability type
            expert_patterns = self._get_expert_patterns(vuln_type)
            
            pattern_matches = []
            for pattern_name, pattern_regex in expert_patterns.items():
                matches = len(re.findall(pattern_regex, asm_content, re.IGNORECASE | re.MULTILINE))
                if matches > 0:
                    pattern_matches.append({
                        'pattern': pattern_name,
                        'matches': matches
                    })
            
            evidence['pattern_matches'] = pattern_matches
            evidence['total_patterns_matched'] = len(pattern_matches)
            evidence['status'] = 'analyzed'
            
            # Calculate exploitability based on pattern matches
            exploitability_score = min(len(pattern_matches) * 0.2, 1.0)
            evidence['exploitability_score'] = exploitability_score
            
            return exploitability_score > 0.4, evidence
            
        except Exception as e:
            evidence['error'] = str(e)
            evidence['status'] = 'analysis_failed'
            return None, evidence
    
    def _get_expert_patterns(self, vuln_type: str) -> Dict[str, str]:
        """Get expert-defined regex patterns for vulnerability types"""
        patterns = {}
        
        if vuln_type == "SPECTRE_V1":
            patterns.update({
                'bounds_check_pattern': r'cmp.*\n.*j[lg].*\n.*(?:ldr|mov).*\[',
                'speculative_load': r'(?:ldr|mov).*\[.*\].*\n.*(?:ldr|mov).*\[',
                'cache_probe': r'(?:dc.*cvau|clflush)',
                'timing_measurement': r'(?:mrs.*cntvct|rdtsc)'
            })
        
        elif vuln_type == "SPECTRE_V2":
            patterns.update({
                'indirect_branch': r'\b(?:br|blr|jmp.*%)',
                'return_misprediction': r'\bret\b',
                'btb_pollution': r'(?:bl|call).*\n.*(?:br|jmp)'
            })
        
        elif vuln_type == "BHI":
            patterns.update({
                'branch_sequence': r'(?:b\.[a-z]+.*\n){3,}',
                'indirect_after_branches': r'(?:b\.[a-z]+.*\n)+.*(?:br|blr)',
                'loop_with_branches': r'(?:loop|cbz|cbnz).*\n(?:.*\n)*.*(?:br|blr)'
            })
        
        elif vuln_type == "L1TF":
            patterns.update({
                'page_fault_pattern': r'(?:brk|hvc|svc)',
                'memory_mapping': r'(?:mmap|munmap|mprotect)',
                'cache_flush': r'(?:dc.*civac|clflush)',
                'fault_suppression': r'(?:csel|cmov)'
            })
        
        elif vuln_type == "MDS":
            patterns.update({
                'store_buffer': r'(?:str|stp).*\n.*(?:ldr|ldp)',
                'load_buffer': r'(?:ldr|ldp).*\n.*(?:ldr|ldp)',
                'memory_disambiguation': r'(?:ldr|str).*\[.*\].*\n.*(?:ldr|str).*\['
            })
        
        return patterns
    
    def _validate_via_context(self, detection: Dict[str, Any]) -> Tuple[Optional[bool], Dict[str, Any]]:
        """Validate by analyzing the context around the vulnerability"""
        evidence = {'method': 'context_analysis'}
        
        repository = detection.get('repository', 'unknown')
        assembly_file = detection.get('assembly_file', '')
        
        # Analyze repository context
        repo_context = self._analyze_repository_context(repository)
        evidence['repository_context'] = repo_context
        
        # Analyze function context
        if os.path.exists(assembly_file):
            function_context = self._analyze_function_context(assembly_file, detection)
            evidence['function_context'] = function_context
        
        # Calculate context-based exploitability
        exploitability_score = 0.0
        
        # Repository factors
        if repo_context.get('is_security_critical', False):
            exploitability_score += 0.3
        if repo_context.get('has_privilege_escalation', False):
            exploitability_score += 0.3
        
        # Function factors
        function_context = evidence.get('function_context', {})
        if function_context.get('is_public_interface', False):
            exploitability_score += 0.2
        if function_context.get('handles_user_input', False):
            exploitability_score += 0.2
        
        evidence['exploitability_score'] = exploitability_score
        evidence['status'] = 'analyzed'
        
        return exploitability_score > 0.4, evidence
    
    def _analyze_repository_context(self, repository: str) -> Dict[str, Any]:
        """Analyze repository context for security implications"""
        context = {}
        
        repo_lower = repository.lower()
        
        # Check if repository is security-critical
        security_keywords = ['kernel', 'crypto', 'ssl', 'tls', 'security', 'auth', 'sudo', 'root']
        context['is_security_critical'] = any(keyword in repo_lower for keyword in security_keywords)
        
        # Check for privilege escalation potential
        privilege_keywords = ['sudo', 'root', 'admin', 'kernel', 'driver', 'system']
        context['has_privilege_escalation'] = any(keyword in repo_lower for keyword in privilege_keywords)
        
        # Check repository type
        if 'darwin-xnu' in repo_lower:
            context['type'] = 'operating_system_kernel'
            context['criticality'] = 'CRITICAL'
        elif any(word in repo_lower for word in ['crypto', 'ssl', 'tls']):
            context['type'] = 'cryptographic_library'
            context['criticality'] = 'HIGH'
        elif any(word in repo_lower for word in ['web', 'server', 'http']):
            context['type'] = 'network_service'
            context['criticality'] = 'MEDIUM'
        else:
            context['type'] = 'general_application'
            context['criticality'] = 'LOW'
        
        return context
    
    def _analyze_function_context(self, assembly_file: str, detection: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze function context around the vulnerability"""
        context = {}
        
        try:
            with open(assembly_file, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # Extract function name from assembly
            lines = content.split('\n')
            function_name = None
            
            for line in lines:
                if ':' in line and not line.strip().startswith('.'):
                    function_name = line.split(':')[0].strip()
                    break
            
            context['function_name'] = function_name or 'unknown'
            
            # Analyze function characteristics
            if function_name:
                func_lower = function_name.lower()
                
                # Check if public interface
                public_indicators = ['main', 'init', 'open', 'read', 'write', 'send', 'recv']
                context['is_public_interface'] = any(indicator in func_lower for indicator in public_indicators)
                
                # Check if handles user input
                input_indicators = ['input', 'parse', 'read', 'recv', 'get', 'copy']
                context['handles_user_input'] = any(indicator in func_lower for indicator in input_indicators)
                
                # Check if privileged function
                priv_indicators = ['sys', 'kernel', 'root', 'admin', 'priv']
                context['is_privileged'] = any(indicator in func_lower for indicator in priv_indicators)
        
        except Exception as e:
            context['error'] = str(e)
        
        return context
    
    def _validate_via_static_tools(self, detection: Dict[str, Any]) -> Tuple[Optional[bool], Dict[str, Any]]:
        """Validate using static analysis tools"""
        evidence = {'method': 'static_analysis_tools'}
        
        # This would integrate with tools like:
        # - clang static analyzer
        # - cppcheck
        # - PVS-Studio
        # - CodeQL
        
        # For now, implement a simplified version
        evidence['status'] = 'not_implemented'
        evidence['note'] = 'Would integrate with external static analysis tools'
        
        return None, evidence
    
    def _validate_via_exploit_sim(self, detection: Dict[str, Any]) -> Tuple[Optional[bool], Dict[str, Any]]:
        """Validate by simulating exploitation"""
        evidence = {'method': 'exploit_simulation'}
        
        # This would involve:
        # - Creating minimal exploit proof-of-concept
        # - Running in controlled environment
        # - Measuring actual exploitation success
        
        evidence['status'] = 'not_implemented'
        evidence['note'] = 'Would require controlled execution environment'
        
        return None, evidence
    
    def _validate_via_compiler(self, detection: Dict[str, Any]) -> Tuple[Optional[bool], Dict[str, Any]]:
        """Validate by analyzing compiler optimizations"""
        evidence = {'method': 'compiler_analysis'}
        
        # This would analyze:
        # - Compiler optimization effects
        # - Whether vulnerability survives compilation
        # - Mitigation effectiveness
        
        evidence['status'] = 'not_implemented'
        evidence['note'] = 'Would analyze compiler optimization effects'
        
        return None, evidence
    
    def _validate_via_comparison(self, detection: Dict[str, Any]) -> Tuple[Optional[bool], Dict[str, Any]]:
        """Validate by comparing with known vulnerabilities"""
        evidence = {'method': 'comparative_analysis'}
        
        # This would compare against:
        # - CVE database
        # - Known vulnerability patterns
        # - Security advisories
        
        evidence['status'] = 'not_implemented'
        evidence['note'] = 'Would compare against CVE database'
        
        return None, evidence
    
    def _generate_validation_notes(self, detection: Dict[str, Any], 
                                 validation_evidence: Dict[str, Any], 
                                 consensus_score: float) -> str:
        """Generate human-readable validation notes"""
        notes = []
        
        notes.append(f"Vulnerability Type: {detection['vulnerability_type']}")
        notes.append(f"Original Confidence: {detection['confidence']:.3f}")
        notes.append(f"Validation Consensus: {consensus_score:.3f}")
        
        # Source code analysis notes
        if 'source_code' in validation_evidence:
            src_evidence = validation_evidence['source_code']
            if src_evidence.get('status') == 'analyzed':
                indicators = src_evidence.get('vulnerability_indicators', [])
                mitigations = src_evidence.get('mitigations_found', [])
                notes.append(f"Source Analysis: {len(indicators)} indicators, {len(mitigations)} mitigations")
        
        # Microarchitectural notes
        if 'microarchitectural' in validation_evidence:
            micro_evidence = validation_evidence['microarchitectural']
            if micro_evidence.get('status') == 'analyzed':
                arch = micro_evidence.get('architecture', 'unknown')
                speculation = micro_evidence.get('speculation_window', {})
                notes.append(f"Microarch Analysis ({arch}): Speculation vulnerable = {speculation.get('speculation_vulnerable', False)}")
        
        # Expert pattern notes
        if 'expert_patterns' in validation_evidence:
            pattern_evidence = validation_evidence['expert_patterns']
            if pattern_evidence.get('status') == 'analyzed':
                matches = pattern_evidence.get('total_patterns_matched', 0)
                notes.append(f"Expert Patterns: {matches} patterns matched")
        
        return "; ".join(notes)
    
    def _save_validation_result(self, result: ValidationResult):
        """Save validation result to database"""
        # Create validation results table if it doesn't exist
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS validation_results (
                id INTEGER PRIMARY KEY,
                detection_id INTEGER,
                vulnerability_type TEXT,
                validation_methods TEXT,
                is_exploitable BOOLEAN,
                confidence_level TEXT,
                evidence TEXT,
                false_positive_likelihood REAL,
                validation_notes TEXT,
                timestamp TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (detection_id) REFERENCES vulnerabilities (id)
            )
        ''')
        
        cursor.execute('''
            INSERT OR REPLACE INTO validation_results 
            (detection_id, vulnerability_type, validation_methods, is_exploitable, 
             confidence_level, evidence, false_positive_likelihood, validation_notes)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            result.detection_id,
            result.vulnerability_type,
            ','.join(result.validation_methods),
            result.is_exploitable,
            result.confidence_level,
            json.dumps(result.evidence),
            result.false_positive_likelihood,
            result.validation_notes
        ))
        
        conn.commit()
        conn.close()
    
    def _generate_validation_report(self, results: List[ValidationResult]):
        """Generate comprehensive validation report"""
        report = {
            'summary': {
                'total_detections_validated': len(results),
                'confirmed_exploitable': len([r for r in results if r.is_exploitable]),
                'likely_false_positives': len([r for r in results if not r.is_exploitable]),
                'high_confidence_validations': len([r for r in results if r.confidence_level == 'HIGH']),
                'validation_methods_used': list(set(method for r in results for method in r.validation_methods))
            },
            'by_vulnerability_type': {},
            'by_confidence_level': {
                'HIGH': [],
                'MEDIUM': [],
                'LOW': []
            },
            'false_positive_analysis': {
                'avg_false_positive_likelihood': sum(r.false_positive_likelihood for r in results) / len(results) if results else 0,
                'high_fp_risk_detections': [r.detection_id for r in results if r.false_positive_likelihood > 0.7]
            }
        }
        
        # Group by vulnerability type
        for result in results:
            vuln_type = result.vulnerability_type
            if vuln_type not in report['by_vulnerability_type']:
                report['by_vulnerability_type'][vuln_type] = {
                    'total': 0,
                    'exploitable': 0,
                    'avg_confidence': 0.0
                }
            
            type_stats = report['by_vulnerability_type'][vuln_type]
            type_stats['total'] += 1
            if result.is_exploitable:
                type_stats['exploitable'] += 1
        
        # Calculate averages
        for vuln_type, stats in report['by_vulnerability_type'].items():
            if stats['total'] > 0:
                stats['exploitability_rate'] = stats['exploitable'] / stats['total']
        
        # Group by confidence
        for result in results:
            report['by_confidence_level'][result.confidence_level].append({
                'detection_id': result.detection_id,
                'vulnerability_type': result.vulnerability_type,
                'is_exploitable': result.is_exploitable,
                'false_positive_likelihood': result.false_positive_likelihood
            })
        
        # Save report
        with open('vulnerability_validation_report.json', 'w') as f:
            json.dump(report, f, indent=2)
        
        # Print summary
        print("\n" + "="*80)
        print("VULNERABILITY VALIDATION REPORT")
        print("="*80)
        print(f"ğŸ“Š Total detections validated: {report['summary']['total_detections_validated']}")
        print(f"âœ… Confirmed exploitable: {report['summary']['confirmed_exploitable']}")
        print(f"âŒ Likely false positives: {report['summary']['likely_false_positives']}")
        print(f"ğŸ¯ High confidence validations: {report['summary']['high_confidence_validations']}")
        
        print(f"\nğŸ“ˆ Validation by vulnerability type:")
        for vuln_type, stats in report['by_vulnerability_type'].items():
            rate = stats.get('exploitability_rate', 0) * 100
            print(f"   {vuln_type}: {stats['exploitable']}/{stats['total']} exploitable ({rate:.1f}%)")
        
        print(f"\nâš ï¸  False Positive Analysis:")
        print(f"   Average FP likelihood: {report['false_positive_analysis']['avg_false_positive_likelihood']:.3f}")
        print(f"   High FP risk detections: {len(report['false_positive_analysis']['high_fp_risk_detections'])}")
        
        self.logger.info(f"Validation report saved to vulnerability_validation_report.json")

def main():
    """Run vulnerability validation"""
    print("ğŸ”¬ Starting Vulnerability Validation Framework")
    
    validator = VulnerabilityValidator()
    results = validator.validate_all_detections()
    
    print(f"\nâœ… Validation complete! Processed {len(results)} detections")

if __name__ == "__main__":
    main()