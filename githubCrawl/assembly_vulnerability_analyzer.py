#!/usr/bin/env python3
"""
Assembly Vulnerability Analyzer
Analyzes unmarked assembly code to identify vulnerable sequences using known vulnerable examples
"""

import os
import pickle
import json
import numpy as np
import sqlite3
from pathlib import Path
from typing import List, Dict, Any, Tuple, Set, Optional
from dataclasses import dataclass, asdict
from collections import defaultdict, Counter
import logging
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import DBSCAN
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import networkx as nx

@dataclass
class VulnerableSequence:
    """Represents a potentially vulnerable assembly sequence"""
    sequence_id: str
    instructions: List[str]
    vulnerability_type: str
    confidence_score: float
    similarity_to_known: float
    source_file: str
    start_position: int
    end_position: int
    evidence: Dict[str, Any]
    gadget_type: str  # 'speculative_load', 'bounds_bypass', 'indirect_branch', etc.

@dataclass 
class VulnerabilityPattern:
    """Pattern extracted from known vulnerable code"""
    pattern_id: str
    vulnerability_type: str
    instruction_sequence: List[str]
    semantic_features: List[str]
    structural_features: Dict[str, Any]
    frequency_signature: Dict[str, float]
    control_flow_pattern: str

class AssemblyVulnerabilityAnalyzer:
    """Comprehensive analyzer for finding vulnerabilities in unmarked assembly code"""
    
    def __init__(self, parsed_assembly_dir: str = "parsed_assembly", 
                 vulnerable_examples_dir: str = "../c_vulns/asm_code"):
        self.parsed_assembly_dir = parsed_assembly_dir
        self.vulnerable_examples_dir = vulnerable_examples_dir
        self.logger = self._setup_logging()
        
        # Analysis components
        self.known_patterns = []
        self.vulnerability_signatures = {}
        self.sequence_embeddings = None
        self.vulnerability_classifier = None
        
        # Configuration
        self.analysis_methods = {
            'pattern_matching': True,
            'sequence_similarity': True,
            'structural_analysis': True,
            'frequency_analysis': True,
            'graph_analysis': True,
            'anomaly_detection': True
        }
        
        self.similarity_thresholds = {
            'SPECTRE_V1': 0.75,
            'SPECTRE_V2': 0.70,
            'L1TF': 0.80,
            'BHI': 0.65,
            'MDS': 0.70,
            'RETBLEED': 0.75,
            'MELTDOWN': 0.80,
            'INCEPTION': 0.60
        }
        
        self.logger.info("Assembly Vulnerability Analyzer initialized")
    
    def _setup_logging(self) -> logging.Logger:
        """Setup logging"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('vulnerability_analysis.log'),
                logging.StreamHandler()
            ]
        )
        return logging.getLogger(__name__)
    
    def analyze_unmarked_assembly(self) -> List[VulnerableSequence]:
        """Main function to analyze unmarked assembly for vulnerabilities"""
        self.logger.info("Starting vulnerability analysis of unmarked assembly code...")
        
        # Step 1: Load and analyze known vulnerable patterns
        self.logger.info("Step 1: Extracting patterns from known vulnerable code")
        self._extract_vulnerability_patterns()
        
        # Step 2: Load parsed assembly data
        self.logger.info("Step 2: Loading parsed assembly data")
        parsed_data = self._load_parsed_assembly_data()
        
        if not parsed_data:
            self.logger.error("No parsed assembly data found")
            return []
        
        # Step 3: Apply multiple analysis methods
        self.logger.info("Step 3: Applying vulnerability detection methods")
        vulnerable_sequences = []
        
        # Method 1: Pattern-based matching
        if self.analysis_methods['pattern_matching']:
            pattern_matches = self._find_pattern_matches(parsed_data)
            vulnerable_sequences.extend(pattern_matches)
            self.logger.info(f"Pattern matching found {len(pattern_matches)} potential vulnerabilities")
        
        # Method 2: Sequence similarity analysis
        if self.analysis_methods['sequence_similarity']:
            similarity_matches = self._find_similarity_matches(parsed_data)
            vulnerable_sequences.extend(similarity_matches)
            self.logger.info(f"Similarity analysis found {len(similarity_matches)} potential vulnerabilities")
        
        # Method 3: Structural analysis
        if self.analysis_methods['structural_analysis']:
            structural_matches = self._find_structural_vulnerabilities(parsed_data)
            vulnerable_sequences.extend(structural_matches)
            self.logger.info(f"Structural analysis found {len(structural_matches)} potential vulnerabilities")
        
        # Method 4: Frequency analysis
        if self.analysis_methods['frequency_analysis']:
            frequency_matches = self._find_frequency_anomalies(parsed_data)
            vulnerable_sequences.extend(frequency_matches)
            self.logger.info(f"Frequency analysis found {len(frequency_matches)} potential vulnerabilities")
        
        # Method 5: Graph-based analysis
        if self.analysis_methods['graph_analysis']:
            graph_matches = self._find_graph_vulnerabilities(parsed_data)
            vulnerable_sequences.extend(graph_matches)
            self.logger.info(f"Graph analysis found {len(graph_matches)} potential vulnerabilities")
        
        # Step 4: Deduplicate and rank results
        self.logger.info("Step 4: Deduplicating and ranking results")
        final_results = self._deduplicate_and_rank(vulnerable_sequences)
        
        # Step 5: Save results
        self._save_analysis_results(final_results)
        
        self.logger.info(f"Analysis complete! Found {len(final_results)} unique vulnerable sequences")
        return final_results
    
    def _extract_vulnerability_patterns(self):
        """Extract patterns from known vulnerable assembly code"""
        if not os.path.exists(self.vulnerable_examples_dir):
            self.logger.warning(f"Vulnerable examples directory not found: {self.vulnerable_examples_dir}")
            return
        
        for asm_file in Path(self.vulnerable_examples_dir).glob("*.s"):
            try:
                vuln_type = self._identify_vulnerability_type(asm_file.name)
                if not vuln_type:
                    continue
                
                # Parse assembly file
                instructions = self._parse_assembly_file(str(asm_file))
                if not instructions:
                    continue
                
                # Extract multiple pattern types
                patterns = self._extract_patterns_from_instructions(instructions, vuln_type, str(asm_file))
                self.known_patterns.extend(patterns)
                
                self.logger.debug(f"Extracted {len(patterns)} patterns from {asm_file.name}")
                
            except Exception as e:
                self.logger.warning(f"Failed to process {asm_file}: {e}")
        
        self.logger.info(f"Extracted {len(self.known_patterns)} total vulnerability patterns")
    
    def _extract_patterns_from_instructions(self, instructions: List[str], 
                                          vuln_type: str, source_file: str) -> List[VulnerabilityPattern]:
        """Extract multiple types of patterns from instruction sequences"""
        patterns = []
        
        # Extract sliding window patterns of different sizes
        window_sizes = [3, 5, 7, 10]
        
        for window_size in window_sizes:
            for i in range(len(instructions) - window_size + 1):
                window = instructions[i:i + window_size]
                
                # Create pattern
                pattern = VulnerabilityPattern(
                    pattern_id=f"{vuln_type}_{Path(source_file).stem}_{i}_{window_size}",
                    vulnerability_type=vuln_type,
                    instruction_sequence=window,
                    semantic_features=self._extract_semantic_features(window),
                    structural_features=self._extract_structural_features(window),
                    frequency_signature=self._extract_frequency_signature(window),
                    control_flow_pattern=self._extract_control_flow_pattern(window)
                )
                
                patterns.append(pattern)
        
        # Extract key vulnerability-specific patterns
        vuln_specific_patterns = self._extract_vulnerability_specific_patterns(instructions, vuln_type, source_file)
        patterns.extend(vuln_specific_patterns)
        
        return patterns
    
    def _extract_vulnerability_specific_patterns(self, instructions: List[str], 
                                               vuln_type: str, source_file: str) -> List[VulnerabilityPattern]:
        """Extract patterns specific to each vulnerability type"""
        patterns = []
        
        if vuln_type == 'SPECTRE_V1':
            # Look for bounds check bypass patterns
            for i in range(len(instructions) - 2):
                if (self._is_compare_instruction(instructions[i]) and
                    self._is_conditional_branch(instructions[i+1]) and
                    self._is_memory_access(instructions[i+2])):
                    
                    pattern = VulnerabilityPattern(
                        pattern_id=f"spectre_v1_bypass_{i}",
                        vulnerability_type=vuln_type,
                        instruction_sequence=instructions[i:i+3],
                        semantic_features=['bounds_check_bypass', 'speculative_load'],
                        structural_features={'has_compare': True, 'has_branch': True, 'has_load': True},
                        frequency_signature=self._extract_frequency_signature(instructions[i:i+3]),
                        control_flow_pattern='compare_branch_load'
                    )
                    patterns.append(pattern)
        
        elif vuln_type == 'SPECTRE_V2':
            # Look for indirect branch patterns
            for i, instr in enumerate(instructions):
                if self._is_indirect_branch(instr):
                    window_start = max(0, i-2)
                    window_end = min(len(instructions), i+3)
                    window = instructions[window_start:window_end]
                    
                    pattern = VulnerabilityPattern(
                        pattern_id=f"spectre_v2_indirect_{i}",
                        vulnerability_type=vuln_type,
                        instruction_sequence=window,
                        semantic_features=['indirect_branch', 'branch_prediction'],
                        structural_features={'has_indirect_branch': True},
                        frequency_signature=self._extract_frequency_signature(window),
                        control_flow_pattern='indirect_branch_sequence'
                    )
                    patterns.append(pattern)
        
        elif vuln_type == 'L1TF':
            # Look for fault-inducing patterns
            for i in range(len(instructions) - 1):
                if (self._is_fault_instruction(instructions[i]) or
                    self._is_privileged_memory_access(instructions[i])):
                    
                    window_start = max(0, i-1)
                    window_end = min(len(instructions), i+3)
                    window = instructions[window_start:window_end]
                    
                    pattern = VulnerabilityPattern(
                        pattern_id=f"l1tf_fault_{i}",
                        vulnerability_type=vuln_type,
                        instruction_sequence=window,
                        semantic_features=['fault_induction', 'privileged_access'],
                        structural_features={'has_fault': True},
                        frequency_signature=self._extract_frequency_signature(window),
                        control_flow_pattern='fault_sequence'
                    )
                    patterns.append(pattern)
        
        elif vuln_type == 'BHI':
            # Look for complex branching patterns
            branch_count = 0
            branch_window = []
            
            for i, instr in enumerate(instructions):
                if self._is_conditional_branch(instr):
                    branch_count += 1
                    branch_window.append(i)
                    
                    # If we have multiple branches in close proximity
                    if len(branch_window) >= 3:
                        window_start = branch_window[0] - 1
                        window_end = min(len(instructions), i + 2)
                        window = instructions[max(0, window_start):window_end]
                        
                        pattern = VulnerabilityPattern(
                            pattern_id=f"bhi_complex_{branch_window[0]}",
                            vulnerability_type=vuln_type,
                            instruction_sequence=window,
                            semantic_features=['complex_branching', 'branch_history'],
                            structural_features={'branch_count': len(branch_window)},
                            frequency_signature=self._extract_frequency_signature(window),
                            control_flow_pattern='complex_branch_sequence'
                        )
                        patterns.append(pattern)
                        
                        # Reset for overlapping patterns
                        branch_window = branch_window[1:]
        
        elif vuln_type == 'MDS':
            # Look for store-load dependencies
            for i in range(len(instructions) - 1):
                if (self._is_store_instruction(instructions[i]) and
                    self._is_load_instruction(instructions[i+1])):
                    
                    window_start = max(0, i-1)
                    window_end = min(len(instructions), i+3)
                    window = instructions[window_start:window_end]
                    
                    pattern = VulnerabilityPattern(
                        pattern_id=f"mds_store_load_{i}",
                        vulnerability_type=vuln_type,
                        instruction_sequence=window,
                        semantic_features=['store_load_dependency', 'memory_disambiguation'],
                        structural_features={'has_store': True, 'has_load': True},
                        frequency_signature=self._extract_frequency_signature(window),
                        control_flow_pattern='store_load_sequence'
                    )
                    patterns.append(pattern)
        
        return patterns
    
    def _load_parsed_assembly_data(self) -> Optional[List[Dict[str, Any]]]:
        """Load the parsed assembly data"""
        try:
            # Load assembly features
            features_path = Path(self.parsed_assembly_dir) / "assembly_features.pkl"
            if features_path.exists():
                self.logger.info(f"Loading assembly features from {features_path}")
                with open(features_path, 'rb') as f:
                    features_data = pickle.load(f)
                
                self.logger.info(f"Loaded features for {len(features_data)} assembly files")
                return features_data
            else:
                self.logger.error(f"Assembly features file not found: {features_path}")
                return None
                
        except Exception as e:
            self.logger.error(f"Failed to load parsed assembly data: {e}")
            return None
    
    def _find_pattern_matches(self, parsed_data: List[Dict[str, Any]]) -> List[VulnerableSequence]:
        """Find exact and approximate pattern matches"""
        vulnerable_sequences = []
        
        for file_data in parsed_data:
            file_path = file_data.get('file_path', 'unknown')
            
            # Extract instructions from raw_instructions
            raw_instructions = file_data.get('raw_instructions', [])
            if not raw_instructions:
                continue
            
            # Convert raw instructions to string format
            instructions = []
            for instr in raw_instructions:
                if isinstance(instr, dict) and 'raw' in instr:
                    instructions.append(instr['raw'])
                elif isinstance(instr, str):
                    instructions.append(instr)
            
            if not instructions:
                continue
            
            for pattern in self.known_patterns:
                matches = self._match_pattern_in_sequence(pattern, instructions, file_path)
                vulnerable_sequences.extend(matches)
        
        return vulnerable_sequences
    
    def _match_pattern_in_sequence(self, pattern: VulnerabilityPattern, 
                                 instructions: List[str], file_path: str) -> List[VulnerableSequence]:
        """Match a specific pattern in an instruction sequence"""
        matches = []
        pattern_length = len(pattern.instruction_sequence)
        
        for i in range(len(instructions) - pattern_length + 1):
            window = instructions[i:i + pattern_length]
            
            # Calculate similarity
            similarity = self._calculate_sequence_similarity(pattern.instruction_sequence, window)
            
            # Check if similarity exceeds threshold
            threshold = self.similarity_thresholds.get(pattern.vulnerability_type, 0.70)
            
            if similarity >= threshold:
                # Additional validation
                if self._validate_pattern_match(pattern, window, instructions, i):
                    vulnerable_seq = VulnerableSequence(
                        sequence_id=f"{Path(file_path).stem}_{i}_{pattern_length}",
                        instructions=window,
                        vulnerability_type=pattern.vulnerability_type,
                        confidence_score=similarity,
                        similarity_to_known=similarity,
                        source_file=file_path,
                        start_position=i,
                        end_position=i + pattern_length,
                        evidence={
                            'matched_pattern': pattern.pattern_id,
                            'similarity_score': similarity,
                            'pattern_type': 'exact_match' if similarity > 0.95 else 'approximate_match'
                        },
                        gadget_type=self._determine_gadget_type(pattern.vulnerability_type, window)
                    )
                    matches.append(vulnerable_seq)
        
        return matches
    
    def _find_similarity_matches(self, parsed_data: List[Dict[str, Any]]) -> List[VulnerableSequence]:
        """Find sequences similar to known vulnerabilities using embeddings"""
        vulnerable_sequences = []
        
        # Create embeddings for all sequences
        self.logger.info("Creating sequence embeddings for similarity analysis")
        all_sequences = []
        sequence_metadata = []
        
        for file_data in parsed_data:
            file_path = file_data.get('file_path', 'unknown')
            raw_instructions = file_data.get('raw_instructions', [])
            if not raw_instructions:
                continue
            
            # Convert raw instructions to string format
            instructions = []
            for instr in raw_instructions:
                if isinstance(instr, dict) and 'raw' in instr:
                    instructions.append(instr['raw'])
                elif isinstance(instr, str):
                    instructions.append(instr)
            
            # Extract sequences of different lengths
            for window_size in [5, 10, 15]:
                for i in range(len(instructions) - window_size + 1):
                    sequence = instructions[i:i + window_size]
                    all_sequences.append(sequence)
                    sequence_metadata.append({
                        'file_path': file_path,
                        'start_pos': i,
                        'end_pos': i + window_size,
                        'window_size': window_size
                    })
        
        if not all_sequences:
            return vulnerable_sequences
        
        # Create embeddings
        sequence_embeddings = self._create_sequence_embeddings(all_sequences)
        known_embeddings = self._create_embeddings_for_known_patterns()
        
        # Find similar sequences
        if known_embeddings is not None and sequence_embeddings is not None:
            similarities = cosine_similarity(sequence_embeddings, known_embeddings)
            
            for i, similarity_scores in enumerate(similarities):
                max_similarity = np.max(similarity_scores)
                best_match_idx = np.argmax(similarity_scores)
                
                if max_similarity >= 0.75:  # High similarity threshold
                    metadata = sequence_metadata[i]
                    sequence = all_sequences[i]
                    matched_pattern = self.known_patterns[best_match_idx]
                    
                    vulnerable_seq = VulnerableSequence(
                        sequence_id=f"sim_{Path(metadata['file_path']).stem}_{metadata['start_pos']}",
                        instructions=sequence,
                        vulnerability_type=matched_pattern.vulnerability_type,
                        confidence_score=max_similarity,
                        similarity_to_known=max_similarity,
                        source_file=metadata['file_path'],
                        start_position=metadata['start_pos'],
                        end_position=metadata['end_pos'],
                        evidence={
                            'similarity_method': 'embedding_cosine',
                            'matched_pattern': matched_pattern.pattern_id,
                            'similarity_score': float(max_similarity)
                        },
                        gadget_type=self._determine_gadget_type(matched_pattern.vulnerability_type, sequence)
                    )
                    vulnerable_sequences.append(vulnerable_seq)
        
        return vulnerable_sequences
    
    def _find_structural_vulnerabilities(self, parsed_data: List[Dict[str, Any]]) -> List[VulnerableSequence]:
        """Find vulnerabilities based on structural analysis"""
        vulnerable_sequences = []
        
        for file_data in parsed_data:
            file_path = file_data.get('file_path', 'unknown')
            raw_instructions = file_data.get('raw_instructions', [])
            if not raw_instructions:
                continue
            
            # Convert raw instructions to string format
            instructions = []
            for instr in raw_instructions:
                if isinstance(instr, dict) and 'raw' in instr:
                    instructions.append(instr['raw'])
                elif isinstance(instr, str):
                    instructions.append(instr)
            
            # Analyze control flow structure
            cfg = self._build_control_flow_graph(instructions)
            
            # Look for vulnerable structural patterns
            vulnerable_blocks = self._analyze_control_flow_vulnerabilities(cfg, instructions)
            
            for block_info in vulnerable_blocks:
                start_pos = block_info['start']
                end_pos = block_info['end']
                vuln_type = block_info['vulnerability_type']
                confidence = block_info['confidence']
                
                sequence = instructions[start_pos:end_pos]
                
                vulnerable_seq = VulnerableSequence(
                    sequence_id=f"struct_{Path(file_path).stem}_{start_pos}",
                    instructions=sequence,
                    vulnerability_type=vuln_type,
                    confidence_score=confidence,
                    similarity_to_known=0.0,  # Not similarity-based
                    source_file=file_path,
                    start_position=start_pos,
                    end_position=end_pos,
                    evidence={
                        'analysis_method': 'structural_analysis',
                        'cfg_properties': block_info.get('properties', {}),
                        'vulnerability_indicators': block_info.get('indicators', [])
                    },
                    gadget_type=block_info.get('gadget_type', 'unknown')
                )
                vulnerable_sequences.append(vulnerable_seq)
        
        return vulnerable_sequences
    
    def _find_frequency_anomalies(self, parsed_data: List[Dict[str, Any]]) -> List[VulnerableSequence]:
        """Find vulnerabilities based on instruction frequency anomalies"""
        vulnerable_sequences = []
        
        # Build frequency profiles for known vulnerabilities
        known_frequency_profiles = self._build_known_frequency_profiles()
        
        for file_data in parsed_data:
            file_path = file_data.get('file_path', 'unknown')
            raw_instructions = file_data.get('raw_instructions', [])
            if not raw_instructions:
                continue
            
            # Convert raw instructions to string format
            instructions = []
            for instr in raw_instructions:
                if isinstance(instr, dict) and 'raw' in instr:
                    instructions.append(instr['raw'])
                elif isinstance(instr, str):
                    instructions.append(instr)
            
            # Analyze frequency patterns in windows
            window_size = 20
            for i in range(len(instructions) - window_size + 1):
                window = instructions[i:i + window_size]
                window_profile = self._create_frequency_profile(window)
                
                # Compare with known profiles
                for vuln_type, known_profile in known_frequency_profiles.items():
                    similarity = self._compare_frequency_profiles(window_profile, known_profile)
                    
                    if similarity > 0.80:  # High frequency similarity
                        vulnerable_seq = VulnerableSequence(
                            sequence_id=f"freq_{Path(file_path).stem}_{i}",
                            instructions=window,
                            vulnerability_type=vuln_type,
                            confidence_score=similarity,
                            similarity_to_known=similarity,
                            source_file=file_path,
                            start_position=i,
                            end_position=i + window_size,
                            evidence={
                                'analysis_method': 'frequency_analysis',
                                'frequency_similarity': similarity,
                                'window_profile': window_profile
                            },
                            gadget_type=self._determine_gadget_type(vuln_type, window)
                        )
                        vulnerable_sequences.append(vulnerable_seq)
        
        return vulnerable_sequences
    
    def _find_graph_vulnerabilities(self, parsed_data: List[Dict[str, Any]]) -> List[VulnerableSequence]:
        """Find vulnerabilities using graph analysis"""
        vulnerable_sequences = []
        
        for file_data in parsed_data:
            file_path = file_data.get('file_path', 'unknown')
            raw_instructions = file_data.get('raw_instructions', [])
            if not raw_instructions:
                continue
            
            # Convert raw instructions to string format
            instructions = []
            for instr in raw_instructions:
                if isinstance(instr, dict) and 'raw' in instr:
                    instructions.append(instr['raw'])
                elif isinstance(instr, str):
                    instructions.append(instr)
            
            # Build control and data flow graphs
            cfg = self._build_control_flow_graph(instructions)
            dfg = self._build_data_flow_graph(instructions)
            
            # Analyze graph properties for vulnerability indicators
            vulnerability_indicators = self._analyze_graph_vulnerabilities(cfg, dfg, instructions)
            
            for indicator in vulnerability_indicators:
                start_pos = indicator['start']
                end_pos = indicator['end']
                vuln_type = indicator['vulnerability_type']
                confidence = indicator['confidence']
                
                sequence = instructions[start_pos:end_pos]
                
                vulnerable_seq = VulnerableSequence(
                    sequence_id=f"graph_{Path(file_path).stem}_{start_pos}",
                    instructions=sequence,
                    vulnerability_type=vuln_type,
                    confidence_score=confidence,
                    similarity_to_known=0.0,
                    source_file=file_path,
                    start_position=start_pos,
                    end_position=end_pos,
                    evidence={
                        'analysis_method': 'graph_analysis',
                        'graph_properties': indicator.get('graph_properties', {}),
                        'vulnerability_indicators': indicator.get('indicators', [])
                    },
                    gadget_type=indicator.get('gadget_type', 'unknown')
                )
                vulnerable_sequences.append(vulnerable_seq)
        
        return vulnerable_sequences
    
    # Helper methods (implementations would be quite long, showing key signatures)
    
    def _identify_vulnerability_type(self, filename: str) -> Optional[str]:
        """Identify vulnerability type from filename"""
        filename_lower = filename.lower()
        vuln_patterns = {
            'spectre_1': 'SPECTRE_V1', 'spectre_v1': 'SPECTRE_V1',
            'spectre_2': 'SPECTRE_V2', 'meltdown': 'MELTDOWN',
            'l1tf': 'L1TF', 'bhi': 'BHI', 'mds': 'MDS',
            'retbleed': 'RETBLEED', 'inception': 'INCEPTION'
        }
        
        for pattern, vuln_type in vuln_patterns.items():
            if pattern in filename_lower:
                return vuln_type
        return None
    
    def _parse_assembly_file(self, filepath: str) -> List[str]:
        """Parse assembly file and return instruction list"""
        instructions = []
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                for line in f:
                    line = line.strip()
                    if (line and not line.startswith('.') and not line.startswith('#') 
                        and not line.endswith(':') and not line.startswith('//')):
                        instructions.append(line)
        except Exception as e:
            self.logger.warning(f"Failed to parse {filepath}: {e}")
        
        return instructions
    
    def _calculate_sequence_similarity(self, seq1: List[str], seq2: List[str]) -> float:
        """Calculate similarity between two instruction sequences"""
        if len(seq1) != len(seq2):
            return 0.0
        
        # Simple similarity based on exact matches and semantic similarity
        exact_matches = sum(1 for a, b in zip(seq1, seq2) if a == b)
        semantic_matches = sum(1 for a, b in zip(seq1, seq2) if self._are_semantically_similar(a, b))
        
        # Combined score
        exact_score = exact_matches / len(seq1)
        semantic_score = semantic_matches / len(seq1)
        
        return (exact_score * 0.7) + (semantic_score * 0.3)
    
    def _are_semantically_similar(self, instr1: str, instr2: str) -> bool:
        """Check if two instructions are semantically similar"""
        # Extract mnemonics
        mnemonic1 = instr1.split()[0] if instr1.split() else ""
        mnemonic2 = instr2.split()[0] if instr2.split() else ""
        
        # Define semantic groups
        semantic_groups = [
            ['ldr', 'ldrb', 'ldrh', 'ldp'],  # Load instructions
            ['str', 'strb', 'strh', 'stp'],  # Store instructions
            ['add', 'sub', 'mul', 'div'],    # Arithmetic
            ['b.eq', 'b.ne', 'b.lt', 'b.gt', 'b.le', 'b.ge'],  # Conditional branches
            ['cmp', 'tst', 'cmn']            # Comparison instructions
        ]
        
        for group in semantic_groups:
            if mnemonic1 in group and mnemonic2 in group:
                return True
        
        return False
    
    def _extract_semantic_features(self, instructions: List[str]) -> List[str]:
        """Extract semantic features from instruction sequence"""
        features = []
        
        for instr in instructions:
            parts = instr.split()
            if not parts:
                continue
            
            mnemonic = parts[0].lower()
            
            # Add instruction type features
            if mnemonic.startswith('ldr'):
                features.append('load_operation')
            elif mnemonic.startswith('str'):
                features.append('store_operation')
            elif mnemonic.startswith('b.'):
                features.append('conditional_branch')
            elif mnemonic == 'cmp':
                features.append('comparison')
            elif mnemonic in ['add', 'sub', 'mul']:
                features.append('arithmetic')
            
            # Add operand features
            operands = ' '.join(parts[1:]) if len(parts) > 1 else ''
            if '[' in operands:
                features.append('memory_access')
            if '#' in operands:
                features.append('immediate_value')
        
        return features
    
    def _extract_structural_features(self, instructions: List[str]) -> Dict[str, Any]:
        """Extract structural features from instruction sequence"""
        features = {
            'length': len(instructions),
            'has_branches': any(instr.split()[0].startswith('b') for instr in instructions if instr.split()),
            'has_memory_ops': any('[' in instr for instr in instructions),
            'has_arithmetic': any(instr.split()[0] in ['add', 'sub', 'mul'] for instr in instructions if instr.split()),
            'branch_count': sum(1 for instr in instructions if instr.split() and instr.split()[0].startswith('b')),
            'memory_op_count': sum(1 for instr in instructions if '[' in instr)
        }
        
        return features
    
    def _extract_frequency_signature(self, instructions: List[str]) -> Dict[str, float]:
        """Extract frequency signature of instruction types"""
        if not instructions:
            return {}
        
        mnemonics = []
        for instr in instructions:
            parts = instr.split()
            if parts:
                mnemonics.append(parts[0].lower())
        
        # Count frequencies
        freq_count = Counter(mnemonics)
        total = len(mnemonics)
        
        # Normalize to frequencies
        freq_signature = {mnemonic: count / total for mnemonic, count in freq_count.items()}
        
        return freq_signature
    
    def _extract_control_flow_pattern(self, instructions: List[str]) -> str:
        """Extract control flow pattern description"""
        patterns = []
        
        for instr in instructions:
            parts = instr.split()
            if not parts:
                continue
            
            mnemonic = parts[0].lower()
            
            if mnemonic == 'cmp':
                patterns.append('CMP')
            elif mnemonic.startswith('b.'):
                patterns.append('CBRANCH')
            elif mnemonic in ['b', 'bl']:
                patterns.append('BRANCH')
            elif mnemonic.startswith('ldr'):
                patterns.append('LOAD')
            elif mnemonic.startswith('str'):
                patterns.append('STORE')
            else:
                patterns.append('OTHER')
        
        return '_'.join(patterns)
    
    def _is_compare_instruction(self, instr: str) -> bool:
        """Check if instruction is a comparison"""
        parts = instr.split()
        return parts and parts[0].lower() in ['cmp', 'tst', 'cmn']
    
    def _is_conditional_branch(self, instr: str) -> bool:
        """Check if instruction is a conditional branch"""
        parts = instr.split()
        return parts and parts[0].lower().startswith('b.') and parts[0].lower() != 'b'
    
    def _is_memory_access(self, instr: str) -> bool:
        """Check if instruction accesses memory"""
        return '[' in instr
    
    def _is_indirect_branch(self, instr: str) -> bool:
        """Check if instruction is an indirect branch"""
        parts = instr.split()
        return parts and parts[0].lower() in ['br', 'blr']
    
    def _is_fault_instruction(self, instr: str) -> bool:
        """Check if instruction can cause faults"""
        parts = instr.split()
        return parts and parts[0].lower() in ['brk', 'hvc', 'svc']
    
    def _is_privileged_memory_access(self, instr: str) -> bool:
        """Check if instruction accesses privileged memory"""
        # This is a simplified check - in practice would be more sophisticated
        return 'system' in instr.lower() or 'kernel' in instr.lower()
    
    def _is_store_instruction(self, instr: str) -> bool:
        """Check if instruction is a store"""
        parts = instr.split()
        return parts and parts[0].lower().startswith('str')
    
    def _is_load_instruction(self, instr: str) -> bool:
        """Check if instruction is a load"""
        parts = instr.split()
        return parts and parts[0].lower().startswith('ldr')
    
    def _validate_pattern_match(self, pattern: VulnerabilityPattern, 
                               window: List[str], full_sequence: List[str], 
                               position: int) -> bool:
        """Validate that a pattern match is likely a real vulnerability"""
        # Additional validation logic
        
        # Check context around the match
        context_start = max(0, position - 5)
        context_end = min(len(full_sequence), position + len(window) + 5)
        context = full_sequence[context_start:context_end]
        
        # Vulnerability-specific validation
        if pattern.vulnerability_type == 'SPECTRE_V1':
            # Ensure we have the right sequence: compare -> branch -> load
            return (self._has_bounds_check_pattern(context) and
                    not self._has_speculation_barriers(context))
        
        elif pattern.vulnerability_type == 'SPECTRE_V2':
            # Ensure we have indirect branches without retpoline
            return (self._has_indirect_branches(context) and
                    not self._has_retpoline_mitigation(context))
        
        # Default validation
        return True
    
    def _has_bounds_check_pattern(self, instructions: List[str]) -> bool:
        """Check for bounds check bypass pattern"""
        for i in range(len(instructions) - 2):
            if (self._is_compare_instruction(instructions[i]) and
                self._is_conditional_branch(instructions[i+1]) and
                self._is_memory_access(instructions[i+2])):
                return True
        return False
    
    def _has_speculation_barriers(self, instructions: List[str]) -> bool:
        """Check for speculation barriers"""
        barrier_instructions = ['dsb', 'isb', 'lfence', 'mfence', 'sfence']
        return any(any(barrier in instr.lower() for barrier in barrier_instructions) 
                  for instr in instructions)
    
    def _has_indirect_branches(self, instructions: List[str]) -> bool:
        """Check for indirect branches"""
        return any(self._is_indirect_branch(instr) for instr in instructions)
    
    def _has_retpoline_mitigation(self, instructions: List[str]) -> bool:
        """Check for retpoline mitigation"""
        return any('retpoline' in instr.lower() for instr in instructions)
    
    def _determine_gadget_type(self, vulnerability_type: str, instructions: List[str]) -> str:
        """Determine the type of gadget"""
        if vulnerability_type == 'SPECTRE_V1':
            if self._has_bounds_check_pattern(instructions):
                return 'bounds_bypass_gadget'
            else:
                return 'speculative_load_gadget'
        elif vulnerability_type == 'SPECTRE_V2':
            return 'indirect_branch_gadget'
        elif vulnerability_type == 'L1TF':
            return 'fault_induction_gadget'
        elif vulnerability_type == 'BHI':
            return 'branch_history_gadget'
        elif vulnerability_type == 'MDS':
            return 'memory_disambiguation_gadget'
        else:
            return 'unknown_gadget'
    
    def _create_sequence_embeddings(self, sequences: List[List[str]]) -> Optional[np.ndarray]:
        """Create embeddings for instruction sequences"""
        try:
            # Simple embedding based on instruction frequencies and n-grams
            all_features = []
            
            for sequence in sequences:
                # Create feature vector
                features = []
                
                # Instruction type frequencies
                mnemonics = [instr.split()[0].lower() if instr.split() else '' for instr in sequence]
                mnemonic_counts = Counter(mnemonics)
                
                # Common instruction types
                common_instructions = ['ldr', 'str', 'add', 'sub', 'cmp', 'b.eq', 'b.ne', 'mov', 'ret']
                for instr_type in common_instructions:
                    features.append(mnemonic_counts.get(instr_type, 0) / len(sequence))
                
                # Structural features
                features.append(sum(1 for instr in sequence if '[' in instr) / len(sequence))  # Memory access ratio
                features.append(sum(1 for instr in sequence if instr.split() and instr.split()[0].startswith('b')) / len(sequence))  # Branch ratio
                
                all_features.append(features)
            
            return np.array(all_features)
            
        except Exception as e:
            self.logger.error(f"Failed to create sequence embeddings: {e}")
            return None
    
    def _create_embeddings_for_known_patterns(self) -> Optional[np.ndarray]:
        """Create embeddings for known vulnerability patterns"""
        if not self.known_patterns:
            return None
        
        sequences = [pattern.instruction_sequence for pattern in self.known_patterns]
        return self._create_sequence_embeddings(sequences)
    
    def _build_control_flow_graph(self, instructions: List[str]) -> nx.DiGraph:
        """Build control flow graph from instructions"""
        cfg = nx.DiGraph()
        
        # Add nodes for each instruction
        for i, instr in enumerate(instructions):
            cfg.add_node(i, instruction=instr)
        
        # Add edges for control flow
        for i, instr in enumerate(instructions):
            parts = instr.split()
            if not parts:
                continue
            
            mnemonic = parts[0].lower()
            
            # Sequential flow
            if i + 1 < len(instructions):
                cfg.add_edge(i, i + 1, edge_type='sequential')
            
            # Branch instructions
            if mnemonic.startswith('b'):
                # Try to find branch target (simplified)
                if len(parts) > 1:
                    target_label = parts[1]
                    # In a real implementation, would resolve label to instruction index
                    # For now, just mark as branch
                    cfg.nodes[i]['is_branch'] = True
        
        return cfg
    
    def _build_data_flow_graph(self, instructions: List[str]) -> nx.DiGraph:
        """Build data flow graph from instructions"""
        dfg = nx.DiGraph()
        
        # Track register definitions and uses
        register_defs = {}  # register -> instruction index
        
        for i, instr in enumerate(instructions):
            parts = instr.split()
            if not parts:
                continue
            
            mnemonic = parts[0].lower()
            
            # Add node
            dfg.add_node(i, instruction=instr)
            
            # Simple register tracking (would be more sophisticated in practice)
            if len(parts) > 1:
                operands = ' '.join(parts[1:])
                
                # Find register uses and definitions
                # This is a simplified version
                if mnemonic in ['ldr', 'mov', 'add', 'sub']:
                    # First operand is usually destination
                    dest_reg = parts[1].split(',')[0] if ',' in parts[1] else parts[1]
                    register_defs[dest_reg] = i
                    
                    # Add edges from previous definitions
                    for j in range(2, len(parts)):
                        reg = parts[j].replace(',', '').replace('[', '').replace(']', '')
                        if reg in register_defs:
                            dfg.add_edge(register_defs[reg], i, edge_type='data_flow')
        
        return dfg
    
    def _analyze_control_flow_vulnerabilities(self, cfg: nx.DiGraph, 
                                            instructions: List[str]) -> List[Dict[str, Any]]:
        """Analyze control flow graph for vulnerability patterns"""
        vulnerabilities = []
        
        # Look for specific patterns in the CFG
        for node in cfg.nodes():
            instr = cfg.nodes[node].get('instruction', '')
            
            # Spectre V1 pattern: compare followed by conditional branch followed by load
            if self._is_compare_instruction(instr):
                successors = list(cfg.successors(node))
                for succ in successors:
                    succ_instr = cfg.nodes[succ].get('instruction', '')
                    if self._is_conditional_branch(succ_instr):
                        # Check for load instruction in speculation window
                        for succ2 in cfg.successors(succ):
                            succ2_instr = cfg.nodes[succ2].get('instruction', '')
                            if self._is_memory_access(succ2_instr):
                                vulnerabilities.append({
                                    'start': node,
                                    'end': succ2 + 1,
                                    'vulnerability_type': 'SPECTRE_V1',
                                    'confidence': 0.75,
                                    'gadget_type': 'bounds_bypass_gadget',
                                    'properties': {
                                        'has_compare': True,
                                        'has_conditional_branch': True,
                                        'has_speculative_load': True
                                    },
                                    'indicators': ['compare_branch_load_pattern']
                                })
        
        return vulnerabilities
    
    def _analyze_graph_vulnerabilities(self, cfg: nx.DiGraph, dfg: nx.DiGraph, 
                                     instructions: List[str]) -> List[Dict[str, Any]]:
        """Analyze combined CFG and DFG for vulnerabilities"""
        vulnerabilities = []
        
        # Look for data flow vulnerabilities
        for node in dfg.nodes():
            # Check for store-load dependencies (MDS)
            instr = dfg.nodes[node].get('instruction', '')
            if self._is_store_instruction(instr):
                # Find dependent loads
                for successor in dfg.successors(node):
                    succ_instr = dfg.nodes[successor].get('instruction', '')
                    if self._is_load_instruction(succ_instr):
                        vulnerabilities.append({
                            'start': node,
                            'end': successor + 1,
                            'vulnerability_type': 'MDS',
                            'confidence': 0.65,
                            'gadget_type': 'memory_disambiguation_gadget',
                            'graph_properties': {
                                'has_store_load_dependency': True,
                                'dependency_distance': successor - node
                            },
                            'indicators': ['store_load_dependency']
                        })
        
        return vulnerabilities
    
    def _build_known_frequency_profiles(self) -> Dict[str, Dict[str, float]]:
        """Build frequency profiles for known vulnerability types"""
        profiles = {}
        
        vuln_instructions = defaultdict(list)
        
        # Group patterns by vulnerability type
        for pattern in self.known_patterns:
            vuln_instructions[pattern.vulnerability_type].extend(pattern.instruction_sequence)
        
        # Create frequency profiles
        for vuln_type, instructions in vuln_instructions.items():
            profiles[vuln_type] = self._create_frequency_profile(instructions)
        
        return profiles
    
    def _create_frequency_profile(self, instructions: List[str]) -> Dict[str, float]:
        """Create frequency profile for instruction sequence"""
        if not instructions:
            return {}
        
        mnemonics = []
        for instr in instructions:
            parts = instr.split()
            if parts:
                mnemonics.append(parts[0].lower())
        
        freq_count = Counter(mnemonics)
        total = len(mnemonics)
        
        return {mnemonic: count / total for mnemonic, count in freq_count.items()}
    
    def _compare_frequency_profiles(self, profile1: Dict[str, float], 
                                  profile2: Dict[str, float]) -> float:
        """Compare two frequency profiles"""
        if not profile1 or not profile2:
            return 0.0
        
        # Get all unique mnemonics
        all_mnemonics = set(profile1.keys()) | set(profile2.keys())
        
        # Create vectors
        vec1 = [profile1.get(mnemonic, 0.0) for mnemonic in all_mnemonics]
        vec2 = [profile2.get(mnemonic, 0.0) for mnemonic in all_mnemonics]
        
        # Calculate cosine similarity
        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        magnitude1 = sum(a * a for a in vec1) ** 0.5
        magnitude2 = sum(b * b for b in vec2) ** 0.5
        
        if magnitude1 == 0 or magnitude2 == 0:
            return 0.0
        
        return dot_product / (magnitude1 * magnitude2)
    
    def _deduplicate_and_rank(self, vulnerable_sequences: List[VulnerableSequence]) -> List[VulnerableSequence]:
        """Remove duplicates and rank by confidence"""
        if not vulnerable_sequences:
            return []
        
        # Group by source file and position
        position_groups = defaultdict(list)
        
        for seq in vulnerable_sequences:
            key = (seq.source_file, seq.start_position, seq.end_position)
            position_groups[key].append(seq)
        
        # Keep the highest confidence detection for each position
        deduplicated = []
        for group in position_groups.values():
            best_seq = max(group, key=lambda x: x.confidence_score)
            deduplicated.append(best_seq)
        
        # Sort by confidence score
        deduplicated.sort(key=lambda x: x.confidence_score, reverse=True)
        
        # Apply additional filtering
        filtered = []
        for seq in deduplicated:
            if self._should_keep_detection(seq):
                filtered.append(seq)
        
        return filtered
    
    def _should_keep_detection(self, seq: VulnerableSequence) -> bool:
        """Determine if a detection should be kept"""
        # Minimum confidence thresholds
        min_confidence = {
            'SPECTRE_V1': 0.70,
            'SPECTRE_V2': 0.65,
            'L1TF': 0.75,
            'BHI': 0.60,
            'MDS': 0.65,
            'RETBLEED': 0.70,
            'MELTDOWN': 0.75,
            'INCEPTION': 0.55
        }
        
        threshold = min_confidence.get(seq.vulnerability_type, 0.60)
        return seq.confidence_score >= threshold
    
    def _save_analysis_results(self, results: List[VulnerableSequence]):
        """Save analysis results to database and files"""
        # Save to database
        self._save_to_database(results)
        
        # Save to JSON for easy inspection
        self._save_to_json(results)
        
        # Generate summary report
        self._generate_summary_report(results)
    
    def _save_to_database(self, results: List[VulnerableSequence]):
        """Save results to SQLite database"""
        db_path = "vulnerability_analysis_results.db"
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # Create table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS vulnerable_sequences (
                id INTEGER PRIMARY KEY,
                sequence_id TEXT UNIQUE,
                vulnerability_type TEXT,
                confidence_score REAL,
                similarity_to_known REAL,
                source_file TEXT,
                start_position INTEGER,
                end_position INTEGER,
                gadget_type TEXT,
                instructions TEXT,
                evidence TEXT,
                timestamp TEXT DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Insert results
        for result in results:
            cursor.execute('''
                INSERT OR REPLACE INTO vulnerable_sequences 
                (sequence_id, vulnerability_type, confidence_score, similarity_to_known,
                 source_file, start_position, end_position, gadget_type, instructions, evidence)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                result.sequence_id,
                result.vulnerability_type,
                result.confidence_score,
                result.similarity_to_known,
                result.source_file,
                result.start_position,
                result.end_position,
                result.gadget_type,
                '\n'.join(result.instructions),
                json.dumps(result.evidence)
            ))
        
        conn.commit()
        conn.close()
        
        self.logger.info(f"Saved {len(results)} vulnerable sequences to {db_path}")
    
    def _save_to_json(self, results: List[VulnerableSequence]):
        """Save results to JSON file"""
        json_data = []
        for result in results:
            json_data.append(asdict(result))
        
        with open('vulnerable_sequences.json', 'w') as f:
            json.dump(json_data, f, indent=2)
        
        self.logger.info(f"Saved results to vulnerable_sequences.json")
    
    def _generate_summary_report(self, results: List[VulnerableSequence]):
        """Generate summary report"""
        if not results:
            self.logger.info("No vulnerabilities found to report")
            return
        
        # Count by vulnerability type
        vuln_counts = Counter(result.vulnerability_type for result in results)
        
        # Count by gadget type
        gadget_counts = Counter(result.gadget_type for result in results)
        
        # Count by confidence level
        high_conf = len([r for r in results if r.confidence_score >= 0.8])
        med_conf = len([r for r in results if 0.6 <= r.confidence_score < 0.8])
        low_conf = len([r for r in results if r.confidence_score < 0.6])
        
        # Generate report
        report = {
            'summary': {
                'total_vulnerabilities': len(results),
                'unique_files_affected': len(set(r.source_file for r in results)),
                'high_confidence': high_conf,
                'medium_confidence': med_conf,
                'low_confidence': low_conf
            },
            'by_vulnerability_type': dict(vuln_counts),
            'by_gadget_type': dict(gadget_counts),
            'top_10_by_confidence': [
                {
                    'sequence_id': r.sequence_id,
                    'vulnerability_type': r.vulnerability_type,
                    'confidence': r.confidence_score,
                    'file': Path(r.source_file).name,
                    'gadget_type': r.gadget_type
                }
                for r in sorted(results, key=lambda x: x.confidence_score, reverse=True)[:10]
            ]
        }
        
        # Save report
        with open('vulnerability_analysis_report.json', 'w') as f:
            json.dump(report, f, indent=2)
        
        # Print summary
        print("\n" + "="*70)
        print(" VULNERABILITY ANALYSIS SUMMARY")
        print("="*70)
        print(f" Total vulnerabilities found: {len(results)}")
        print(f" Files affected: {len(set(r.source_file for r in results))}")
        print(f" High confidence (80%): {high_conf}")
        print(f" Medium confidence (60-80%): {med_conf}")
        print(f"  Low confidence (<60%): {low_conf}")
        
        print(f"\n By vulnerability type:")
        for vuln_type, count in vuln_counts.most_common():
            print(f"   {vuln_type}: {count}")
        
        print(f"\n By gadget type:")
        for gadget_type, count in gadget_counts.most_common():
            print(f"   {gadget_type}: {count}")
        
        self.logger.info("Summary report saved to vulnerability_analysis_report.json")

def main():
    """Run the vulnerability analysis"""
    print(" Starting Assembly Vulnerability Analysis")
    print("="*60)
    
    analyzer = AssemblyVulnerabilityAnalyzer()
    
    # Run the analysis
    vulnerable_sequences = analyzer.analyze_unmarked_assembly()
    
    print(f"\n Analysis complete!")
    print(f"Found {len(vulnerable_sequences)} potentially vulnerable sequences")
    
    if vulnerable_sequences:
        print("\nTop 5 findings:")
        for i, seq in enumerate(vulnerable_sequences[:5], 1):
            print(f"{i}. {seq.vulnerability_type} in {Path(seq.source_file).name}")
            print(f"   Confidence: {seq.confidence_score:.3f}")
            print(f"   Gadget: {seq.gadget_type}")
            print(f"   Position: {seq.start_position}-{seq.end_position}")

if __name__ == "__main__":
    main()